---
title: "Mixed Model"
author: "Jin"
date: "2019-03"
output:
  bookdown::html_document2:
    number_sections: true
    seq_numbering: true
    fig_caption: true
    highlight: haddock
    theme: null
    md_extensions: +east_asian_line_breaks
    keep_md: true
    toc: false
    pandoc_args: ["--filter", "pandoc-crossref", "-M", "eqnPrefix="]
  bookdown::word_document2:
    fig_caption: true
    reference_docx: ./style/word-styles-02.docx
    md_extensions: +east_asian_line_breaks
    pandoc_args: ["--filter", "pandoc-crossref"]
  bookdown::pdf_document2:
    keep_tex: yes
    toc: false
    latex_engine: xelatex
    md_extensions: +east_asian_line_breaks
    pandoc_args: ["--listing", "--filter", "pandoc-crossref"]
css: ./style/markdown.css
autoEqnLabels: true
eqnPrefixTemplate: ($$i$$)
linkReferences: true
bibliography: Bibfile.bib
csl: ./style/chinese-gb7714-2005-numeric.csl
link-citations: true
---

**TODO**


```{r setup,echo=F}
knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = FALSE, results = 'hide')
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
```

```{r prepare}
rm(list=ls())
options(digits=4)
options(scipen=100)
graphics.off()
Sys.setlocale("LC_ALL", "Chinese")
```



# 简介：为什么用混合模型？

有时候混合模型被称为重复测量模型，有时候被称为分层模型。有时候混合模型用来分析类别
和面板数据，有时候用来分析纵向数据。

经典统计中一个典型的假设就是观测值来自相同总体且独立同分布。混合模型的数据具有更复
杂的多级分层结构。在水平和类别之间的观测值是独立的，但是在每个类别之间的观测值是相
依的，因为它们属于相同的子总体。因此，我们谈到两种变异来源：类别之间和类别之内。

混合模型也适合分析纵向数据，每个时间序列构成一个单独的曲线，一个类别。混合模型非常
适合生物医学数据，这些数据显示出对刺激和治疗的响应的异质性。混合模型的一个优点就是
通过引进多层随机效应真正组合数据的能力。混合模型是一个非线性统计模型，主要是由于参
数方差的存在，因此需要特殊的理论处理。

使用混合模型的目的：（1）处理复杂的聚类或纵向数据；（2）使用多个变异来源对数据建模；
（3）模拟生物多样性和异质性；（4）频率学派和贝叶斯方法的折中；（5）惩罚似然函数的
统计模型；（6）为HAIC提供理论基础；（7）处理高维参数；（8）作为解决不适定问题的统计
模型，包括图片重建问题；（9）模拟形状和图像。

## 聚类数据的混合效应

$\{(x_k,y_k),k=1,\cdots,K\}$ 表示几种商品的价格和销量数据。绘制 $y$ 对 $x$ 的图显示出
有负斜率的近似线性关系。经典统计假设 $(x_k,y_k)$ 是独立同分布的，回归直线为 $E(y|x)=\alpha+\beta x$。
然而，其他人可能会说，我们处理的是类别数据，一个类别是一种商品。如果将所有商品放在一起，
则价格和销量的图显示的具有负斜率的近似直线，但如果将所有商品分类，不同类别的商品单独
绘制价格和销量的图，则显示的是几条具有正斜率的直线，每条直线代表一种商品。前者为经典
统计，后者为混合效应方法。

经典统计假设模型是：

$$y_k=\alpha+\beta x_k+\epsilon_k,\quad k=1,\cdots,K$$ {#eq:model1.1}

其中 $\{\epsilon_k\}$ 是服从零均值同方差的独立同分布的随机变量。换句话说，它假定数据
来自类似的同类商品。销售问题的适当模型是假定每种商品都有自己的商品特定销量（统计术语
就是截距），也就是说

$$y_{ij}=\alpha_i+\beta x_{ij}+\epsilon_{ij},\quad i=1,\cdots,N,j=1,\cdots,n_i$$ {#eq:model1.2}

$i$ 代表第 $i$ 个商品，$j$ 表示第 $i$ 个商品的第 $j$ 次观测，$n_i$ 是第 $i$ 个商品的
观测数量，$\alpha_i$ 是商品特定截距。总观测数量是 $K=\sum_{i=1}^n n_i$。关于误差项 $\epsilon_i$，
假定它具有相同的方差 $\sigma^2$，且独立同分布。

很明显，[@eq:model1.2]比[@eq:model1.1]复杂，在 $\alpha_i=\alpha$ 的情况下，我们可以由
[@eq:model1.2]得到[@eq:model1.1]。混合效应模型的中心假设就是截距 $\{\alpha_i,i=1,\cdots,N\}$ 
是随机的，且属于能够被表示成第二个等式的一般总体

$$\alpha_i=\alpha+b_i$$ {#eq:model1.3}

其中 $\alpha$ 是一般总体的销量（截距），$b_i$ 是随机效应，或解释为来自一般总体商品销量
和具体商品销量的偏差。

结合[@eq:model1.2]和[@eq:model1.3]可以定义线性混合效应模型，参数 $\alpha$ 和 $\beta$
是固定效应（一般总体参数），$b_i$ 是随机效应，零均值，方差为 $\sigma_b^2$，且和 $\epsilon_{ij}$
独立。这是个分层模型或有随机系数的模型。由[@eq:model1.2]和[@eq:model1.3]定义的模型可以写为下式

$$y_{ij}=\alpha+\beta x_{ij}+\eta_{ij},\quad i=1,\cdots,N,j=1,\cdots,n_i$$  {#eq:model1.4}

其中 $\eta_{ij}=\epsilon_{ij}+b_i$ 是组合的随机误差。就像[@eq:model1.4]，相同商品的观测和
相关系数相关：

$$\rho=\frac{var(b_i)}{var(b_i+\epsilon_{ij})}=\frac{\sigma_b^2}{\sigma^2+\sigma_b^2}$$ {#eq:model1.5}

但是观测值在不同的商品（来自不同的类）上并不相关。混合效应模型中，变异来自两方面：类内部的变异
$\sigma^2$ 和类与类之间的变异 $\sigma_b^2$。

观测值 $\{y_{i1},y_{i2},\cdots,y_{i{n_i}}\}$ 也可以被解释为重复测量，因此[@eq:model1.4]也被
称为重复测量模型。尤其适用于纵向数据，观察对象是基于时间进行观测的。

忽略了类别结构可能会导致错误分析。对于类别数据线性混合效应模型是一个合适的模型，它
包含两个变异，类间和类内。

## ANOVA，方差成分和混合模型

混合模型可能被视为方差分析，方差成分和回归模型的组合。比如，最简单的，表格数据的
单因素方差分析

$$y_{ij}=\beta_i+\epsilon_{ij},\quad i=1,\cdots,N,j=1,\cdots,n_i$$  {#eq:model1.6}

其中 $N$ 是单元数量（对象或类别数），$n_i$ 是每个单元中观测值数量，$\epsilon_{ij}$
具有零均值同方差的独立同分布的误差项。一个重要的假设就是方差分析中 $\{\beta_1,\cdots,\beta_N\}$
是固定参数。因此，对每个单元，观测值 $\{y_{i1},y_{i2},\cdots,y_{in_i}\}$ 可以被视为是重复的，
因为它们是独立同分布的，且均值为 $\beta_i$。另外一个假设就是单元是相同的，或 $H_0:\beta_1=\cdots=\beta_N$。

方差分析模型是线性回归模型的特例

$$y=x \beta+\epsilon$$ {#eq:model1.7}

$y$ 是 $K\times 1$ 维的观测值向量，$x$ 是 $K\times m$ 维的设计矩阵，$\beta$ 是 $m\times 1$ 
维的参数向量。比如，如果 $y_{ij}$ 表示 $y$中的元素，$K=\sum_{i=1}^Nn_i$，设计矩阵的元素是0或1，$m=N$，
则单因素方差分析[@eq:model1.6]可以表示成回归分析[@eq:model1.7]的形式。所有的方差分析模型
都有两个重要的特征：（a）参数 $\{\beta_i,i=1,\cdots,m\}$由普通最小二乘估计，
（b）F检验是线性假设检验。[@eq:model1.6]和[@eq:model1.7]也可以称为固定效应模型。

假定 $\beta_i$ 随机，且独立同分布于均值为 $\beta$，方差为 $\sigma_\beta^2$ 的正态分布。
$\beta_i=\beta+b_i$可以得到方差成分模型：

$$y_{ij}=\beta+b_i+\epsilon_{ij}$$ {#eq:model1.8}

其中 $b_i$ 被称为随机效应。方差分析是固定效应模型，方差成分是随机效应模型。虽然
[@eq:model1.6]和[@eq:model1.8]看起来相似，但是有不同的统计性质。在方差分析中，
观测值是独立的，但是在方差成分模型中，观测值在每个单元内是相关的且相关系数等于
$\frac{\sigma_\beta^2}{\sigma^2+\sigma_\beta^2}$。根据高斯-马尔科夫理论，对于[@eq:model1.6]，
普通最小二乘和极大似然估计是一致的并且是有效的，但是对于[@eq:model1.8]就不适用。并且，
如果 $n_i$ 不同，极大似然估计就没有封闭解。方差分析中的原假设 $H_0:\beta_1=\cdots=\beta_N$ 
变成 $H_0:\sigma_\beta^2=0$，并且F检验也不能直接应用，因为它需要大量修改。当单元数相对小
的时候（比如，$N<min(n_i)$），方差分析模型是适合的。当单元数量相对较大（比如，$N>max(n_i)$），
方差成分模型可能会更好。

混合模型可能被视为方差分析和方差成分模型的组合。比如，考虑 $i=1,\cdots,N$ 个人在时刻
$t_{i1},t_{i2},\cdots,t_{in_i}$ 测量血压的问题。如果 $y_{ij}$ 表示第 $i$ 个人在时刻 $t_{ij}$
时的血压，方差成分模型可能会比较好，因为它反映了不同的人血压不同，但是，同时，一个人也
可以说是一般总体的血压 $\beta$。现在除了知道血压之外，还知道性别、年龄等信息。为了反映
测量是在相当长的时间内，我们将 $t_{ij}$ 并入完全协变量 $x_{ij}$ 中。将方差成分模型扩展
为混合效应模型

$$y_{ij}=x_{ij}^{\prime} \beta+b_i+\epsilon_{ij}$$   {#eq:model1.9}

这和[@eq:model1.7]的相似性非常明显。

通常来说，线性混合模型可以写为

$$y_i=X_i\beta+Z_i b_i+\epsilon_i,\quad i=1,\cdots,N$$ {#eq:model1.10}

$b_i$ 是随机效应向量，$cov(b_i)=\sigma^2D$，$Z_i$ 是设计矩阵。比如，对于[@eq:model1.9]，
随机效应是标量且 $Z_i=1$。方差参数 $\sigma^2$ 和 $D$ 是未知的并且受限于一般总体参数 $\beta$ 的估计。

通过将向量 $\{y_i\}$ 和矩阵 $\{X_i\}$ 组合为 $\sum n_i \times 1$ 的向量 $y$ 和 $\sum n_i \times m$ 
的矩阵 $X$，令 $Z=diag(Z_1,\cdots,Z_N)$，[@eq:model1.10]就可以写为一个方程，$y=X\beta+Zb+\epsilon$。

虽然[@eq:model1.10]看起来是线性的，但是方差未知使其成为一个具有详细估计方法的非线性统计模型。
通常我们假定随机效应和误差项是正态分布，所以[@eq:model1.10]可以写的更加紧凑

$$y_i \sim N(X_i \beta,\sigma^2(I+Z_iDZ_i^{\prime})),\quad i=1,\cdots,N$$  {#eq:model1.11}

$y_i$ 服从多元正态分布，均值为 $X_i\beta$，方差为矩阵 $\sigma^2(I+Z_iDZ_i')$。如果 $D$
已知，由高斯-马尔科夫理论知，广义最小二乘估计值

$$\hat{\beta}=(\sum_{i=1}^N X^{\prime}(I+Z_iDZ_i^{\prime})^{-1}X_i)^{-1}(\sum_{i=1}^NX^{\prime}(I+Z_iDZ_i^{\prime})^{-1}y_i) $$

是有效的。但是随机效应的方差-协方差矩阵是未知的，它的估计在混合效应模型中是一个
主要的主题。考虑方差参数的两个估计族：极大似然估计和二次非迭代无分布估计，包括
MINQUE，方差最小二乘和矩量法。

## 混合效应模型的其他特例

线性混合模型[@eq:model1.10]另一个重要的特例就是有随机系数的回归模型

$$y_i=X_ia_i+\epsilon_i,\quad a_i=\beta+b_i,\quad i=1,\cdots,N$$  {#eq:model1.12}

上式可以用来分析横截面（面板）数据，$y_i$ 是长度为 $n$ 的时间序列，$i$ 表示经济部门。一个有趣的特例是当数据是平衡的时候，$X_i=Z$ 对于平衡数据，
普通和广义最小二乘会有相同的估计结果。增长曲线中，$a_i=A_i\beta+b_i$ 
且 $A_i$ 是设计矩阵。有时候只能指定 $a_i$，因此其他系数可以是任意系数。
比如在[@eq:model1.9]中只有截距项是随机的。

另外一个特例就是 $n_i=1$ 的时候，这就导致了有异方差的线性回归，
$y_i=\beta^\prime x_i+\eta_i$，其中 $\eta_i$ 零均值，方差为 
$var(\eta_i)=\sigma^2(1+dz_i^2)$，$d$ 是需要估计的参数。

## 贝叶斯和频率学派的折中

贝叶斯和混合模型都是基于分层模型，但是前者必须指定所有参数的值，后者的参数需要从数据中估计。

$y$ 为观测数据，在贝叶斯方法中，模型以分层方式指定为

$$y|\theta \sim L(y|\theta)$$  {#eq:model1.13}

$$\theta \sim G(\theta)$$  {#eq:model1.14}

[@eq:model1.13]通过密度函数 $L$ 定义了给定 $\theta$ 后 $y$ 的条件分布。[@eq:model1.14]
通过密度函数 $G$ 定义了 $\theta$ 的先验分布。因为 $G$ 通常是一个分布族，因此指定 $G$
的参数被称为超参数。因此，贝叶斯方法假定参数 $\theta$ 是随机的且密度函数 $L$ 和 $G$
必须是给定的。贝叶斯框架中主要的计算问题是归一化参数的计算

$$A=\int L(y|\theta)G(\theta)d\theta$$ {#eq:model1.15}

在后验密度中

$$p(\theta|y)=\frac{1}{A}L(y|\theta)G(\theta)$$ {#eq:model1.16}

很明显需要确定 $A$ 使[@eq:model1.16]表面下定义的面积为1。一种最流行的方法就是马尔
可夫链蒙特卡洛模拟。

混合模型中允许有非随机参数 $\tau$，也就是说

$$y|\theta \sim L(y|\theta,\tau)$$  {#eq:model1.17}

$$\theta \sim G(\theta,\tau)$$ {#eq:model1.18}

在贝叶斯框架下，$\tau$ 是已知的并且是超参数。当 $\tau$ 未知时，我们就得到频率学派模型，
$\tau$ 需要被估计，可以用极大似然估计。与贝叶斯一样，整合问题成了一个技术问题，因为极大
似然最大化边际似然

$$L(\tau)=\int L(y|\theta,\tau)G(\theta,\tau)d\theta$$  {#eq:model1.19}

在混合模型框架下，$\theta$ 是随机效应参数，$\tau$ 是固定效应参数。
随机效应是不可观测的，整合在[@eq:model1.19]中，$\tau$ 是估计的。因此，
归一化常数在混合模型中有重要作用。在 $\tau$ 估计出来之后，
我们应用标准贝叶斯公式，比如后验密度，后验均值等。在混合模型中，
后验均值被称为随机效应的估计。

总的来说，混合模型结合了频率学派和贝叶斯方法的主要特征。一方面，混合模型假定分层模型
且参数是随机的。另一方面，超参数 $\tau$ 是由数据估计的。

通过正态分布下的线性模型论述贝叶斯方法和混合模型的不同

$$y|\beta \sim N(X \beta,\sigma^2I_n)$$  {#eq:model1.20}

$$\beta \sim N(0,\sigma_\beta^2I_m)$$ {#eq:model1.21}

这些方程是一般贝叶斯模型[@eq:model1.13]和[@eq:model1.14]的特例。总的来说，如果回归系数
向量 $\beta$ 已知，$y$ 就服从多元正态分布，均值为 $X\beta$，方差为 $\sigma^2$。
从[@eq:model1.21]可知，$\beta$ 的先验分布也是正态的，均值为0，方差为 $\sigma_\beta^2$。
为了使贝叶斯规范完整，需要提供方差参数 $\sigma^2$ 和 $\sigma_\beta^2$ 的分布。通常，
可以使用gamma分布，密度函数为 $\Gamma^{-1}(\alpha)\lambda^{\alpha}t^{\alpha-1}e^{-\lambda t}$，
其中 $\alpha$ 和 $\lambda$ 是已知的正参数。

混合模型中方差参数需要估计，可以使用极大似然，也可以使用无偏二次估计。比如，使用
极大似然方法，[@eq:model1.20]和[@eq:model1.21]就意味着如下模型

$$y\sim N(0,\sigma^2(I+dXX^\prime))$$

其中 $d=\frac{\sigma_\beta^2}{\sigma^2}$ 标准化的方差参数。在贝叶斯方法中，
参数 $\sigma^2$ 和 $d$ 必须是通过已知分布指定的。在混合模型中，我们将其视为
未知参数需要通过极大似然进行估计。对数似然函数为

$$l(\sigma^2,d)=-0.5n ln\sigma^2-0.5ln|I+dXX^\prime|-0.5\sigma^{-2}y^\prime(I+dXX^\prime)^{-1}y$$

我们得到 $\sigma^2=n^{-1}y^{\prime}(I+dXX^\prime)^{-1}y$。将其代入 $l$，可以得到对数似然函数简化为只含一个参数的函数

$$l(d)=-0.5nlny^\prime(I_n+dXX^\prime)^{-1}y-0.5ln|I+dXX^{\prime}|$$

贝叶斯方法中的超参数在混合模型中是估计出来的。在参数值确定了之后，可以计算后验
分布，也为正态分布，且均值为 $\hat{\beta}=\hat{d}X^\prime(I+\hat{d}XX^\prime)^{-1}y$。
使用降维公式，可以将其表示为 $\hat{\beta}=X^\prime X+\hat{d}^{-1}I_mX^\prime y$。

## 惩罚似然和混合效应

令 $y$ 表示一个 $n$ 维的观测向量，密度函数为 $L$ 且其依赖于 $k$ 维参数 $b$，$k$ 可能很大。
定义 $l(b;y)$ 为对数似然函数，$L(b;y)$ 为似然函数。如果 $n$ 接近 $k$，极大似然解

$$\mathop{\max}\limits_b l(b;y)$$   {#eq:model1.22}

转化成了一个不适定问题。为了改善[@eq:model1.22]，引进一个惩罚项，极大化惩罚似然

$$\mathop{\max}\limits_b[l(b;y)+\rho g(b)]$$   {#eq:model1.23}

$\rho$ 是非负的惩罚系数，$g(b)$ 是惩罚函数。通常 $g(b)=-\|b\|^2$，因此惩罚似然是极小化下式

$$-l(b;y)+\rho \|b\|^2$$  {#eq:model1.24}

如果 $\rho=0$，我们就会得到之前的不适定问题。如果 $\rho \to \infty$，就会得到 $b=0$。
因此，通过改变 $\rho$，可以得到很多解，从不稳定的极大似然估计到0。

为了估计 $\rho$，我们假定 $b$ 是随机的，则 $L(b;y)$ 是条件似然。$G$ 是密度函数，所以
$b$ 的密度就是 $\omega^{-k}G(\omega^{-1}b)$，$\omega$是一个正的尺度参数。可以表示成
分层统计模型

$$y|b \sim L,\quad b \sim G$$ {#eq:model1.25}

因为只有 $y$ 的观测是可以得到的，我们就需要去求得边际分布

$$\int_{R^k} L(b;y)\omega^{-k}G(\omega^{-1}b)db$$

随机变量 $b$ 被整合出来。令 $g=ln G$，边际对数似然可以表示为

$$l(\omega)=-kln\omega+ln\int_{R^k}e^{l(b;y)+g(\omega^{-1}b)}db$$  {#eq:model1.26}

对 $l$ 求极大值求得 $\hat{\omega}$。拉普拉斯近似可以表示极大似然和惩罚似然之间的关系

$$\int_{R^k}e^{h(b)}db\backsimeq(2\pi)^{k/2}e^{h_{max}} |-\frac{\partial^2h}{\partial b^2}|_{b=b_{max}}|^{-1/2}$$ {#eq:model1.27}

$h_{max}=h(b_{max})$，$|H|$ 是负的海塞矩阵在最大值处的行列式，$H=-\frac{\partial^2h}{\partial b^2}$。
将这个近似代入[eq:model1.26]中，得到

$$l(\omega)\backsimeq-kln\omega+l(b;y)+g(\omega^{-1}b)-0.5ln|H|$$

最后，假定 $ln|H|$ 随 $b$ 的变化变化很小，则边际对数似然可以近似为 

$$l(\omega)\backsimeq-kln\omega+l(b;y)+g(\omega^{-1}b)$$ {#eq:model1.28}

在特定的例子中 $\omega$ 是已知的，极大化边际对数似然就等价于极大化

$$l(b;y)+g(\omega^{-1}b)$$  {#eq:model1.29}

在混合模型的文献中，[@eq:model1.28]也被称为拟似然估计。对于线性模型，惩罚对数
似然是精确的，对于非线性模型，惩罚对数似然是原始对数似然的近似，这种联系可以
由拉普拉斯近似进行连接。

## HAIC

AIC是普遍使用的模型选择准则

$$AIC=-2l_{max}+2k$$  {#eq:model1.30}

$l_{max}$ 是对数似然函数的极大值，$k$ 是未知参数个数。AIC越小，模型越好。AIC对非嵌套模型
尤其有用，如果模型是嵌套的，就需要应用标准统计假设技术。注意到，[@eq:model1.30]中对于对数
似然函数有一个惩罚项。比如，考虑线性回归

$$y=X\beta+\epsilon$$  {#eq:model1.31}

$\beta$ 是 $k$ 维的参数向量，$\epsilon_i$ 是独立同分布的正态随机变量，均值为0，
方差为 $\sigma^2$，$i=1,2,\cdots,n$。假定所有候选模型选用相同的观测值数量（$n=$常数），则

$$AIC=nln\hat{\sigma}^2+2k$$ {#eq:model1.32}

$\hat{\sigma}^2=n^{-1}\|y-X\hat{\beta_{LS}}\|^2$ 是回归方差，$\hat{\beta}$ 是最小二乘估计。

一些人认为AIC估计可能存在明显的偏差，有人建议用$k(k+1)(k+2)/(n-k-2)$ 代替 $2k$，也有人建议
$AIC=-2l_{max}+a(n)k$，其中 $a(n)$ 是样本量 $n$ 的函数。

当存在多重共线性的时候，AIC不能很好的选择模型。

在惩罚对数似然函数中，假设参数的先验分布是正态分布，则

$$l\backsimeq-\frac{k}{2}ln\omega^2+l(b;y)-\frac{1}{2\omega^2}\|b\|^2$$

方差的对数似然函数值在 $\omega^2=\|b\|^2/ k$ 处取得最大值，所以HAIC准则为

$$HAIC=H-2l_{max}+2k=H+AIC$$ {#eq:model1.33}

$$H=k(ln(\|\hat{b_{ML}}\|^2/ k)-1)$$ {#eq:model1.34}

当比较两个有不同估计参数 $k$ 的模型时，AIC有较好的比较效果，但是当模型存在不适定问题时，
它就不能区分有相同参数和拟合数量的模型。HAIC在任何情况下都适用。

## 惩罚光滑

令 $y_1,y_2,\cdots,y_n$ 表示在时刻 $i=1,2,\cdots,n$ 观测的时间序列数据。我们想要找到 $\mu_1,\mu_2,\cdots,\mu_n$ 

$$y_i=\mu_i+\epsilon_i\quad i=1,\cdots,n$$ {#eq:model1.35}

$\epsilon_i$ 是独立同分布的随机变量，均值为0，常数方差 $\sigma^2$。很明显，$\mu_i$
没有任何限制，这个问题的解为$\mu_i=y_i$。用几个惩罚函数限制 $\mu_i$。普遍使用的是以下准则

$$\sum_{i=1}^n(y_i-\mu_i)^2+\rho\sum_{i=1}^{n-1}(\mu_{i+1}-2\mu_i+\mu_{i-1})^2$$  {#eq:model1.36}

$\rho$ 是正的参数，为惩罚系数。上式第一部分是普通的平方和，第二部分是对曲率 $\{\mu_i\}$
的惩罚。事实上，如果第二部分是0，则 $\mu_{i+1}=2\mu_i-\mu_{i-1}$，通过推断，我们用 $\mu_1,\mu_2$ 推断 
$\{\mu_i,i=3,\cdots,n\}$ 得到 $\mu_{i+1}=i\mu_2-(i-1)\mu_1=i(\mu_2-\mu_1)+\mu_1$。但是这是 $i$ 
的线性函数，所以第二部分在 $\{\mu_i\}$ 的非线性部分加了惩罚项。$\mu_{i+1}-2\mu_i+\mu_{i-1}$ 
可以视为二阶导数的离散近似，因此，第二部分可以被视为函数 $\int[\mu^{\prime\prime}(x)]^2dx$ 惩罚非线性性。

因为[@eq:model1.36]是个二次函数，它的极小值可以通过矩阵的逆表示。事实上，引进一个 $n\times (n-2)$ 的矩阵 
$Q$，其元素为1和2，平行于主对角线，比如，

$$Q=\begin{bmatrix} 1 & 0 & 0 & 0 \\ -2&1&0&0 \\ 1&-2&1&0\\ 0&1&-2&1\\ 0&0&1&-2\\0&0&0&1\\ \end{bmatrix}$$

$n=6$。可以看到向量 $Q^\prime\mu$ 的第 $i$ 个元素是 $\mu_i-2\mu_{i+1}+\mu_{i+2}$，
因此[@eq:model1.36]第二个部分可以表示为 $\mu^\prime QQ^\prime \mu$，函数将变为极小化下式

$$\|y-\mu\|^2+\rho\mu^\prime QQ^\prime\mu$$  {#eq:model1.37}

$X$ 是 $n\times2$ 维的矩阵，第一列是1，第二列是 $1,2,\cdots,n$。可以发现 $Q^\prime X=0$，
所以在[@eq:model1.37]中可以替代 $\mu=X\beta+b_n$，得到一个相等的极小化问题

$$\|y-X\beta-b_n\|^2+\rho b_n^\prime QQ^\prime b_n^\prime$$ {#eq:model1.38}

$\beta$ 和 $b_n$ 是 $n\times1$ 维的向量。区别于 $\beta$，我们得到 $\hat{\beta}=(X^\prime X)^{-1}X^\prime y$

$$b_n=(I+\rho QQ^\prime)^{-1}(y-X\hat{\beta})$$  {#eq:model1.39}

则惩罚光滑的解由下式给出

$$\hat{\mu}=X\hat{\beta}+\hat{b_n}=(I+\rho QQ^\prime)^{-1}y$$  {#eq:model1.40}

上式中，如果 $\rho=0$，我们可以得到 $\hat{\mu}=y$。当$\rho \to \infty$ 时，我们得到
最小二乘预测 $\hat{\mu}=X\hat{\beta}$。惩罚系数的选择是很重要的，比如交叉验证，AIC信息准则。
接下来我们将会阐述基于线性混合效应模型这个参数怎么选择。

现在我们建立了一个线性混合效应模型，惩罚系数自动选择。因为 $X$ 是固定效应矩阵，我们可能会将 $b$
视为具有不相关成分的随机效应，产生如下线性混合效应模型：

$$y=X\beta+Zb+\epsilon$$

$$Z=Q(Q^\prime Q)^{-1},\quad b\sim N(0,\sigma^2dI_{n-2}),\quad \epsilon\sim N(0,\sigma^2I_n)$$

该模型是一般线性混合效应模型[@eq:model1.10]的特例，$N=1,D=dI_m$。简单来说，这个模型可以写为 
$y\sim N(X\beta,\sigma^2(I+dZZ^\prime))$。可以有几种估计方法：普通或限制极大似然估计，
无分布二次估计如方差最小二乘，MINQUE，或矩量法。在 $d$ 估计出来之后，在混合效应模型中
有两个等价的方式去估计 $\beta$ 和 $b$：

$$\hat{\beta}=(X^\prime (I+\hat{d}ZZ^\prime)^{-1}X)^{-1}X^\prime(I+\hat{d}ZZ^\prime)^{-1}y$$   {#eq:model1.41}

$$\hat{b}=\hat{d}(I_{n-2}+\hat{d}Z^\prime Z)^{-1}Z^\prime (y-X\hat{\beta})$$  {#eq:model1.42}

或者是如下惩罚函数最小

$$\|y-X\beta-Zb\|^2+d^{-1}\|b\|^2$$

为了显示出[@eq:model1.41],[@eq:model1.42]和[@eq:model1.40]的等价性，这里 $\rho=1/d$，
我们使用降维公式。因为 $Z^\prime X=0$ 简化了最小二乘估计和混合效应模型的预测，
$X\hat{\beta}+Z\hat{b}$ 就产生了[@eq:model1.40]。

在一个不等的情况下，$x_1<x_2<\cdots<x_n$ 而不是 $\mu_{i+1}-2\mu_i+\mu_{i-1}=\delta_i$，我们有

$$\frac{\mu_{i+1}-\mu_i}{x_{i+1}-x_i}-\frac{\mu_i-\mu_{i-1}}{x_i-x_{i-1}}=\delta_i,\quad i=12,\cdots,n-1$$  {#eq:model1.43}

$\mu_0$ 和$\mu_{n+1}$ 是固定且未知的，$\delta_i \sim N(0,\sigma^2d)$。这个模型可以应用在
更一般的样条回归中，协变量是 $U$，比如，$y=U\beta+Zb+\epsilon$，$\mu$ 满足[@eq:model1.43]。
再一次引进一个合适的带宽矩阵$Q$，我们将这个模型降为混合效应模型 $y=X\beta+Zb+\epsilon$，
$X$ 是由两个向量组成，1和 $x$，通过矩阵 $U$ 增强。这个模型也可以应用在回归系数中，比如
$y_i=\beta^\prime u_i+\mu_i x_i+\epsilon_i$，其中 $\{\mu_i\}$ 满足[@eq:model1.43]，
$u_i$ 是一个调整的协变量向量。

## 惩罚多项式拟合

混合模型可以应用在任何一个需要有惩罚项的回归模型中，这里我们对一个有高自由度的多项式
全参数模型使用这种方法。不是一般性，令 $x_1<x_2<\cdots<x_n$

$$y_i=\beta^\prime u_i+\sum_{k=2}^K b_{k-1}x_i^k+\epsilon_i,\quad i=1,\cdots,n$$ {#eq:model1.44}

$\{u_i\}$ 是解释变量，$b_k,k=1,\cdots,K-1$ 是未知系数。之后会解释从第二个自由度开始，
即 $k=2$ 开始，线性部分 $(x)$ 能够由固定效应 $(u_i)$ 表示。假设 $K$ 足够大且已知。
为了避免多重共线性，我们可以使用第 $k$ 个自由度的多项式 $P_k(x_i)$ 代替 $x_i^k$，得到

$$y_i=\beta^\prime u_i+\sum_{i=2}^K b_{k-1}P_k(x_i)+\epsilon_i$$  {#eq:model1.45}

$\sum_{i=1}^n P_k(x_i)P_j(x_i)=0,k\neq j$，$\sum_{i=1}^n P_k^2(x_i)=1$，这就进一步简化了运算。
引进一个 $(K-1)\times1$ 的向量 $p_i=(P_2(x_i),P_3(x_i),\cdots,P_K(x_i))^\prime$，我们得到
一个回归模型 $y_i|b=\beta^\prime u_i+b^\prime p_i+\epsilon_i$，
结合多项式系数的先验分布，作为随机效应处理，我们得到混合效应模型

$$y|b=U\beta+Pb+\epsilon,\quad b\sim N(0,\sigma^2D)$$ {#eq:model1.46}

指定 $D$ 矩阵可能有几种方式。首先可以假定 $D$ 和单位矩阵是成比例的。其次，$D$
可能是非结构化的，但是可能包含很多估计的参数，$K(K-1)/2$。第三，我们可以惩罚高自由度，
也就是说，非线性性，就像在[@eq:model1.36]中那样一样。我们采取最后一种方式，注意到初等
多项式 $x^k$ 的曲率和二阶导数有关。因为固定 $x$，$x^k$ 的二阶导数和 $k(k-1)$ 成比例，
我们假定矩阵 $D$ 的对角线元素是曲率的倒数。比如，假定 $\{b_k\}$ 与 $K=4$ 不相关，我们有

$$D=d \begin{bmatrix} [2(2-1)]^{-2} & 0 & 0\\ 0& [3(3-1)]^{-2} & 0\\ 0 & 0 & [4(4-1)]^{-2}\\ \end{bmatrix}$$

$d$ 是标准化的未知方差。这就意味着 $b_{k-1},k=2,\cdots,K$ 的方差随着 $k$ 的增大而减小，
并与 $[k(k-1)]^{-2}$ 成比例。将其整合在[@eq:model1.46]中，我们得到
   
$$y\sim N(U\beta,\sigma^2(I+dPDP^\prime)) $$  {#eq:model1.47}

如果标准化的方差 $d$ 已知，我们将通过下式估计 $\beta$ 和 $b$

$$\|y-U\beta-Pb\|^2+d^{-2}b^\prime D^{-1}b \Rightarrow \mathop{\min\limits_{\beta,b}}$$

因此 $1/d$ 作为惩罚系数。如果标准化方差很大，惩罚项的贡献就可以被忽略，我们就可以得到
一个不受限的[@eq:model1.45]的最小二乘估计。如果 $d\to0$，我们将会抑制多项式部分，简单地
估计回归 $y=U\beta+\epsilon$。因此，$d$ 的估计就变成惩罚多项式拟合优先考虑的事情。

## 限制参数

本节讲述如何应用混合模型处理非线性模型中的多维度，即有很多参数的logistic回归模型。

营养流行病学中出现了大量参数的问题。具体来讲，让我们考虑饮食对二元变量 $y$ 健康状况
的影响：如果健康状况是令人满意的，$y=0$，否则，$y=1$。令$z_{i1},z_{i2},\cdots,z_{im}$ 
表示第 $i$ 个人每月消耗低 $j$ 种食物的数量，$i=1,\cdots,n$。为了确定饮食效果，可以
建立logistic回归模型

$$Pr(y_i=1)=\frac{exp(\beta_0+\beta_1z_{i1}+\cdots+\beta_mz_{im})}{1+exp(\beta_0+\beta_1z_{i1}+\cdots+\beta_mz_{im})}$$  {#eq:model1.48}

如果一种食物增加了概率，$\beta>0$（坏食物），否则，$\beta<0$（好食物）。通常 $y$ 
表示一种疾病是否存在，$z$ 从问卷调查中获得。如果食物的数量很多（比如，超过了观测值的数量），
我们获得的系数值就会有很大的标准误。因此，为了获得有意义的估计，食物系数应该受限或受到惩罚。
我们在此讨论的问题是：究竟哪种食物有助于提升健康状况？为了限制大量的参数，我们引入非线性
混合模型。

举例说明，如果第 $i$ 个人腺瘤复发，因变量 $y_i=1$，否则，$y_i=0$，$i=1,\cdots,n=751$ 个人。
因此，根据[@eq:model1.48]，大的正系数表示增加风险的食物（坏的食物），负系数表示阻止风险的
食物（好的食物）。我们考虑 $m=11$ 种食物。

混合模型是有未知食物方差的贝叶斯模型。具体来讲，我们将[@eq:model1.48]视为条件模型：如果
$\beta=(\beta_1,\cdots,\beta_m)^\prime$ 已知，腺瘤复发的概率就由[@eq:model1.48]表示。
我们假定食物并不影响复发，先验可以写为

$$\beta\sim N(0,\sigma^2I)$$  {#eq:model1.49}

这就意味着回归系数的均值是0，它们是独立的，且变异是 $\sigma^2$。[@eq:model1.48]
和[@eq:model1.49]定义了广义线性混合模型。为了估计 $\sigma^2$，我们获得了边际似然函数

$$l(\beta_0,\sigma^2)=(2\pi \sigma^2)^{-m/2}\int_{R^m}e^{l(\beta_0,\beta)-0.5\sigma^{-2}\|\beta\|^2}d\beta$$  {#eq:model1.50}

$l(\beta_0,\beta)$ 是[@eq:model1.48]普通对数似然函数。不能直接整合因为维数 $m$ 很大。
因此，应使用积分[@eq:model1.50]的近似方法，比如拉普拉斯近似和拟似然估计。在估计了 
$\hat{\sigma}$ 和 $\hat{\beta_0}$ 之后，我们通过极大化惩罚似然函数获得 $\beta$ 的后验均值

$$l(\beta_0,\beta)-0.5\hat{\sigma}^{-2}\|\beta\|^2$$  {#eq:model1.51}

注意到在贝叶斯方法中我们需要定义 $\beta_0$ 和 $\sigma^2$，在混合模型中，我们用数据来估计它们。

## 不适定问题，Thikhonov正则化，和混合效应

混合模型可能被认为是解决不适定问题的工具。考虑非线性模型

$$y_i=f_i(\theta)+\epsilon_i,\quad i=1,2,\cdots,n$$   {#eq:model1.52}

为了获得 $\theta$ 的估计，通常使用最小二乘准则 $\sum_{i=1}^n(y_i-f_i(\theta))^2\Rightarrow min$。然而，因为 $m \approx n$ 且函数 $f_i(\theta)$ 是非线性的，$\theta$ 的估计就会出现问题。因此，将这个问题就称为不适定问题。Tikhonov建议用二次项增强平方和

$$T(\theta)=\sum_{i=1}^n(y_i-f_i(\theta))^2+\rho\|\theta\|^2$$ {#eq:model1.53}

$\rho$ 被称为正则化参数（$\rho>0$）。原来的不适定问题变为一个适定问题。可以将其应用于病态线性系统的解，积分方程，密度估计和图像重构中。

## 总结

通常，数据含有类别结构（面板或表格数据）。古典统计学假定观测值是独立同分布的。在
类别数据中，这个假定可能会导致错误的结果。相反，混合效应模型假定变异有两方面来源：
类间和类内。混合模型中系数有两种类型：一般总体和具体类别。前者和经典统计有相同的含义，
后者是随机的，且由后验均值进行估计。

线性混合效应模型可能被视为方差成分模型和回归分析的一般化。当类别数量小，给个类别中
观测值较大时，我们将具体的类别系数视为固定的，应用含哑变量的普通回归分析，就像方差
分析一样。这样的模型被称为固定效应模型。相反，当模型中类别数大，但每个类别内的观测值
相对较小时，随机效应模型将更加合适，此时，具体类别系数是随机的。

混合模型技术可以看成频率学派和贝叶斯方法的折中。和贝叶斯方法相似，混合模型以分层方式
指定模型，假定参数是随机的。但是不像贝叶斯方法，超参数是用数据估计的。贝叶斯方法中要
知道先验分布，但先验分布中可能含有未知参数，这个未知参数就由数据进行估计。

惩罚似然经常用来解决参数维度较大的问题。我们证明了惩罚似然可能来自混合模型作为应用
拉普拉斯近似后边际似然的近似。然而，惩罚系数像普通参数一样通过极大似然进行估计。

AIC准则用来比较统计模型并选择最有用的信息。AIC的表达式是惩罚对数似然函数的形式，惩罚
等于参数向量的维度。AIC的一个缺点就是它不能惩罚不适定统计问题，就像在线性回归中解释
变量间的多重共线性。我们扩展了一个健康的AIC准则去处理不适定问题，因为惩罚项包含了参数
向量的平均长度。结果，在相同的对数似然函数值和参数个数的模型中，HAIC将会选择最短参数
向量长度的模型。

由于惩罚模型会导致惩罚似然，因此它可以应用惩罚光滑和多项式进行拟合。更重要的是，惩罚
系数的选择可以通过使用混合模型从数据中估计系数得以解决。在惩罚光滑中，我们通过bending
energy限制参数，通过二阶导数进行多项式拟合。

混合模型可以处理参数多维度的问题。比如，如果一个统计模型包含很多参数，我们可能会假定
先验参数零均值方差未知。通过拉普拉斯近似从数据中估计方差，我们会得到惩罚似然。我们
通过饮食和logistic回归说明了这种方法，其中食物数量可能会很大。

Tikhonov正则化旨在通过增加一个二次惩罚项用适定问题代替不适定问题。然而，惩罚系数的
选择是个问题。虽然T正则化在贝叶斯框架下有很好的统计解释，但是惩罚系数仍然是一个遗留
问题。结合感兴趣的参数 $\theta$ ，非线性混合模型可以从已知数据中估计惩罚系数。

# 线性混合效应模型实例分析

## 基本模型设定

研究礼貌程度与声音音调高低的关系，可建立如下模型：

$$\text{pitch}\sim \text{politeness}+\epsilon$$

考虑性别差异：

$$\text{pitch}\sim \text{politeness}+\text{sex}+\epsilon$$

对每个个体进行多次测量，即每个个体都进行多次有礼貌和无礼貌的回答。这违反了线性回归
模型中独立性的假定，相同个体的多次回答不能被视为是独立的。处理这个问题的方法就是为
每个个体加入随机效应。将随机效应添加到固定效应中建立混合模型，为每个个体增加随机效
应，表示由于个体差异所导致的特殊变化。模型形式为：

$$\text{pitch}\sim \text{politeness}+\text{sex}+(1|\text{subject})+\epsilon$$

$(1|subject)$ 表示假定每个个体的截距项不同，1代表截距。

再考虑不同的情景。例如，向教授寻求帮助（有礼貌条件），向同龄人寻求帮助（非正式条件），
来不及时间紧迫的情况等，都在有礼貌和非正式之间划分，共7个不同的情景。和个体差异相似，
我们也考虑情景不同的差异：

$$\text{pitch}\sim \text{politeness}+\text{sex}+(1|\text{subject})+(1|\text{item})+\epsilon$$

用R进行相应分析：

```{r fig1,eval=T,fig.cap = "箱线图", dev='png'}
politeness<-read.csv(".\\data\\politeness_data.csv")
head(politeness)
boxplot(frequency~attitude*gender,col=c("white","lightgray"),politeness)
```

以上图形表明，礼貌情况下音调的中位数比非正式条件的低。男性和女性在两种情况下的音调高低有交叉。

根据以下命令进行模型建立：
```{r eval=T,echo=T}
library(lme4)
politeness.model<-lmer(frequency~attitude+(1|subject)+(1|scenario),data=politeness)
summary(politeness.model)
```

Random effects部分表示由随机效应导致的因变量的变异程度。可以发现，scenario对
因变量的变异程度比subject低。由箱线图也可以看出，个体间比情景间有更多的差异。
最后的Residul表示 $\epsilon$ 造成的变异。Fixed effects部分表示固定效应导致
因变量的变异程度。attitudepol表示礼貌类别的斜率。-19.695表示从非正式到礼貌需要
降低19.695HZ。202.588表示非正式场合音调的平均值。

将性别作为固定效应加入模型：
```{r eval=T,echo=T}
politeness.model<-lmer(frequency~attitude+gender+(1|subject)+(1|scenario),data=politeness)
summary(politeness.model)
```

Random effects中，比较之前没有固定性别的模型，subject的变异急剧下降。
这是因为性别引起的变化与个体引起的变化混淆了。在Fixed effects中，男性女性的
差异是109HZ，截距代表男性在非正式场合的音调。

## 统计显著性：似然比检验

在R中建立空模型及全模型进行似然比检验：
```{r eval=T,echo=T}
politeness.null<-lmer(frequency~gender+(1|subject)+(1|scenario),data=politeness,REML=FALSE)
politeness.model<-lmer(frequency~attitude+gender+(1|subject)+(1|scenario),data=politeness,
                       REML=FALSE)
anova(politeness.null,politeness.model)
```

结果显示，全模型更好一点。类似还可以进行其他模型的对比。

随机斜率和随机截距

```{r eval=T,echo=T}
coef(politeness.model)
```

以上结果显示，每个个体和每个情景都有不同的截距。并不是所有的个体和情景的固定效应
（态度和性别）都是相同的。这个模型就是所谓的随机截距模型。我们考虑了音调的基线差异，
但是我们假设无论礼貌的影响如何，对所有个体和情景都是相同的。事实上，这不是一个有效
的假设，一些情景下礼貌程度或多或少会有些不同。也就是说，礼貌的效应会因情景的不同而
不同。比如说，一些人比较礼貌，一些人没有那么礼貌。所以，我们需要的是一个随机斜率模型，
个体和情景不仅仅允许有不同的截距，也允许有不同的斜率。

```{r eval=T,echo=T}
politeness.model<-lmer(frequency~attitude+gender+(1+attitude|subject)+(1+attitude|scenario),
                       data=politeness,REML=FALSE)
coef(politeness.model)
```

$(1+attitude|subject)$ 表示不同的基线频率水平（截距用1表示）以及态度在特定情况下
的不同反应。现在，对于每个个体和情景，attitudepol列（礼貌效应的个体和情景系数）
是不同的。然而，它始终是负的，并且许多值非常相似。这意味着尽管存在个体差异，但礼貌
对语调的影响也是一致的：对于我们来说，在礼貌地讲话时声音往往会下降，但对于某些人来说，
它比其他人稍微下降得多。再看性别那一列，系数并没有改变，这是因为我们并没有指定性别
效应的不同个体和不同情景的随机斜率。

```{r eval=T,echo=T}
politeness.null<-lmer(frequency~gender+(1+attitude|subject)+(1+attitude|scenario),data=politeness,
                      REML=FALSE)
anova(politeness.null,politeness.model)
```

结果表明，完全模型显著。

## 假设

所有线性模型中的假设都可以直接应用在混合模型中。共线性、强影响点、异方差等，在R中验证
这些假设的方法和线性模型相同，通过残差图，残差图的直方图或Q-Q图进行验证。

```{r fig2,eval=T,fig.cap = "残差检验", dev='png'}
par(mfrow=c(1,3))
plot(fitted(politeness.model),residuals(politeness.model))
hist(residuals(politeness.model))
qqnorm(residuals(politeness.model))
```

独立性是最重要的假设，用混合模型取代线性模型解决数据中的不独立问题是最主要的原因之一。
如果遗漏重要的固定效应或随机效应，混合模型也违反了独立性。比如，如果用不包含随机效应
subject的模型分析我们的数据，我们的模型将不会知道每个个体有多个回答。这就等价于违反了
独立性假定。所以，谨慎地选择固定效应和随机效应变量，也可以解决不独立的问题。


