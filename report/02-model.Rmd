---
title: "开题报告"
author: "Li"
date: '2019-04-15'
output: pdf_document
css: ./style/markdown.css
bibliography: Bibfile.bib
eqnPrefixTemplate: ($$i$$)
link-citations: yes
linkReferences: yes
notice: '@*'
csl: ./style/chinese-gb7714-2005-numeric.csl
autoEqnLabels: no
---


```{r setup, echo=F}

################# 第 2 章 R 程序代码  ####################


knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = FALSE, results = 'hide')
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
```

```{r prepare}
rm(list=ls())
options(digits=4)
options(scipen=100)
graphics.off()
Sys.setlocale("LC_ALL", "Chinese")
```


# 广义可加混合模型背景与设定 {#sec:chap-2}
这一部分先介绍几个基础回归模型，包括广义线性模型，非参数回归模型及线性混合模型的
概念。在这些概念的基础上，就可以讨论广义线性模型、半参数方法和混合模型三者结合得
到的广义可加混合模型(GAMM)。本章基础模型部分主要参考了金林(2016)的著作
[@Jin2016]。

## 广义线性模型(GLM) {#sec:glm}
在实际数据分析过程中，经常会遇到分类数据。分类数据模型，像Logistic回归模型和泊松回
归模型的用途很广。在统计理论上，分类数据模型一般属于广义线性模型(Generalized
Linear Model，GLM)。广义线性模型是经典线性模型的自然推广，最先由Nelder和
Wedderburn在1972年提出[@nelder1972generalized]。广义线性模型为这些常用统计模型提
供了一套统一的框架。许多在统计分析中常见的模型都可以看作是广义线性模型的特殊情况，
例如线性回归和方差分析，处理定性因变量的logit和probit模型，用于分析计数数据的对
数线性模型和泊松回归模型，生存数据分析中一些常见统计模型等。上面这些模型虽然名称
各异，但它们具有一些共同的特征，例如它们的本质都具有线性，它们的参数估计可以使用相同的
估计方法。这些共同点使得我们可以把这些模型放在一起作为一类模型来研究，而不是把它
们看着是无关联的模型。下面我们就讨论广义线性模型框架。这一部分内容主要参考了
McCullagh，Nelder (1989)[@mccullagh1989generalized]，Fahrmeir，
Tutz(1994)[@fahrmeir1994multivariate]，Lindsey (1997)[@lindsey1997applying]，
Olsson(2002)[@olsson2002generalized]和Dobson，
Barnnet(2008)[@dobson2008introduction]等人关于广义线性模型的著作。

作为讨论广义线性模型的基础,下面先给出经典线性模型。

$Y_{1},\cdots, Y_{n}$是 $n$个相互独立的随机向量,并且$Y_{i} \sim
\bm{\mathcal{N}}(\mu_{i},\sigma^{2}), i=1,\cdots, n$， $Y_{1},\cdots,
Y_{n}$的一次样本实现值为$y_{1},\cdots,y_{n}$。 令$\bm Y=(Y_{1},\cdots,
Y_{n})^T$， $\bm y=(y_{1},\cdots,y_{n})^{T}$， $\bm \mu=(\mu_{1},
\cdots, \mu_{n})^{T}$，即有$\mathbb{E}(\bm Y)= \bm \mu$。现有$p$个确定
性变量$x_{1},\cdots,x_{p}$，每个变量也有$n$个值，用矩阵$\bm X$来表示这
$n\times p$个值，即 

$$\bm X= \left [
    \begin{array}{cccc}
      x_{11}& x_{12}& \ldots & x_{1p}\\
      x_{21}& x_{22}& \ldots & x_{2p}\\
      \vdots& \vdots& \ddots & \vdots\\
      x_{n1}& x_{n2} & \ldots & x_{np}
    \end{array}
  \right]$$
  
其中 $x_{1}$ 变量一般取1，即 $\bm X$的第一列一般全部为1。此外，用 $\bm
\beta=(\beta_{1}, \cdots, \beta_{p})^{T}$表示 $p$ 个固定未知参数。以 $\bm
Y$为因变量，以 $x_{1}, \cdots, x_{p}$为自变量，建立线性回归模型有
$$\mathbb{E}(\bm Y)=\bm \mu, \text{而} \bm \mu=\bm X \bm \beta.$${#eq:semipara-2}

经典线性模型的假设可以归纳为四点：(1)线性，即因变量的期望是自变量参数
的线性函数；(2)独立性， $Y_{1},\cdots, Y_{n}$ 之间是独立的；(3)正态性，
 $Y_{1},\cdots, Y_{n}$ 都服从正态分布；(4)方差齐性， $Y_{1},\cdots,
Y_{n}$ 的方差为固定常数。

### 广义线性模型三个组成部分
为了简化从经典线性模型向广义线性模型的过渡，我们把公式[@eq:semipara-2]分解为以下三个部分的设定：

1\. 随机部分：这部分是关于因变量的分布或者是随机项的结构。在经典线性模型中，
$\bm Y$ 的分量相互独立，且都服从正态分布， $\mathbb{E}(\bm Y)=\bm \mu$ ，方差为固定常数
 $\sigma^{2}$ 。

2\. 系统部分：这部分是自变量的一个函数，以期用它来解释因变量的期望。在经典线性模型
中，系统部分是自变量的线性组合，我们把这个线性函数称为线性预测子(linear
predictor)，用$\bm \eta$来表示，即
$$\label{eq:semipara-3} \bm \eta= \bm{X\beta}.$$

3\. 联接函数：联接函数是联接随机部分和系统部分的工具。在经典线性模型中，联接函数
为恒等函数，即 
$$\label{eq:semipara-5} \bm \mu = \bm \eta.$$ 

如果我们有
$$\eta_{i}=g(\mu_{i})$$
那么我们把函数$g(\cdot)$称为联接函数(link function)。

与经典线性模型相同，广义线性模型也由随机部分、系统部分和联接函数三部分
组成。但广义线性模型在随机部分和联接函数两个方面对经典线性模型进行了推
广。广义线性模型的随机部分可以不是正态分布，而是推广到指数分布簇；广义
线性模型的联接函数不必是恒等函数，可以推广到任意单调可微函数。

#### 指数分布簇

指数分布簇是一大类包括许多常见分布的分布集合，它包括许多常见的分布，如正态
分布，指数分布，二项分布，泊松分布，伽玛分布和逆正态分布等等。而常见的
不属于指数分布簇的分布有$t$分布和柯西分布。指数分布簇的概率密度函数具有以
下形式 
$$
  f(y;\theta,\phi)=
  \exp \left[\frac{y\theta-b(\theta)}{a(\phi)}+c(y,\phi) \right],$${#eq:semipara-6}
  
其中 $a(\cdot)$ ， $b(\cdot)$ 和 $c(\cdot)$ 是一些具体的函数。当 $\phi$ 已知时，
参数 $\theta$ 被称为标准参数(canonical parameter)。当 $\phi$ 未知
时，具有以上形式概率密度函数的分布有可能属于具有两个参数的指数分布簇，
也有可能不再属于指数分布簇。例如正态分布的概率密度函数可以写成指数分布
簇密度函数的形式 
$$\begin{aligned}
  \label{eq:semipara-8}
  f(y;\mu,\sigma^{2})&=\frac{1}{\sqrt{2\pi\sigma^{2}}}
  \exp\left[-\frac{(y-\mu)^{2}}{2\sigma^{2}}\right]  \\
  &=\exp\left \{ \left[y\mu-\frac{\mu^{2}}{2} \right]
      \frac{1}{\sigma^{2}}-\frac{y^{2}}{2\sigma^{2}}-\frac{1}{2}\log(2\pi\sigma^{2}) \right\}\end{aligned}$$
此时$\theta=\mu$， $\phi=\sigma^{2}$，并且 
$$\label{eq:semipara-9}
  a(\phi)=\phi, \quad b(\theta)=\theta^{2}/2,\quad c(y,\phi)=-[y^{2}/
  \phi+\log(2\pi \phi)]/2.$$

指数分布簇有一些良好的性质，服从指数分布簇的随机变量的期望和方差都与其
概率密度函数中的函数$b(\theta)$有关。

#### 联接函数

联接函数$g(\cdot)$把线性预测子$\bm \eta$和因变量$\bm Y$的期望$\bm
\mu$联接起来，其一般形式为$g(\bm \mu)=\bm \eta=\bm{X\beta}$。函
数$g(\cdot)$必须单调可微。对于单调函数，我们可以定义其反函
数$g^{-1}(\cdot)$，此时有$g^{-1}(g(\mu))=\mu$。联接函数的选择依赖于数据
的类型。在经典线性模型中，因变量服从连续的正态分布，期望和线性预测子是
相同的，所以恒等联接是合理的，此时$\bm \eta$和 $\bm \mu$都可以取实数轴上
的任意值。对于计数数据和泊松分布，期望必然大于0，此时使用恒等联接函数则
不太合适，因为$\bm \eta$可以为负值而$\bm \mu$不可以。对于泊松分布，联接
函数可以为对数函数，即$\bm \eta=\log \bm \mu$，它的逆函数为$\bm
\mu=e^{\bm \eta}$。对于二项分布，我们有$0<\bm \mu<1$。联接函数应该把区
间$[0,1]$映射到整个实数轴上。这时主要考虑三种联接函数：logit，probit和
互补log-log联接。此外，当期望为正值时，一种重要的联接函数是指数函数。下
面我们把重要的联接函数列举出来。

1\. 恒等联接：$\bm \eta=\bm \mu$，逆函数为$\bm \mu=\bm \eta$，
此时$\bm \mu$可以为任意实数值。

2\. log联接：$\bm \eta=\log \bm \mu$，逆函数为$\bm \mu= e^{\bm
\eta}$，此时$\bm \mu > 0$。

3\. logit联接：$\bm \eta=\log[\bm \mu/(1-\bm \mu)]$，逆函数为
$\bm \mu=[e^{\bm \eta}/(1+e^{\bm \eta})]$，此时$\bm \mu$的取值范围为$[0,1]$。

4\. probit联接：$\bm \eta=\Phi^{-1}(\bm \mu)$，其中
$\Phi(\cdot)$是标准正态分布累计分布函数，逆函数为$\bm \mu=\Phi(\bm
\eta)$，此时$\bm \mu$的取值范围为$[0,1]$。

5\. 互补log-log联接：$\bm \eta=\log[-\log(1-\bm \mu)]$，逆函数为
$\bm \mu=1-\exp[-\exp(\bm \eta)]$，此时$\bm \mu$的取值范围为$[0,1]$。

6\. 指数函数联接：
$$\bm \eta=\frac{\bm \mu^{\lambda}-1}{\lambda},\quad \lambda \neq 0，$$
其极限值为 
$$\bm \eta=\log \bm \mu; \text{当}\lambda \rightarrow 0.$$
或者写成 
$$\bm \eta= \left \{
    \begin{array}{lr}
      \bm \mu^{\lambda},& \lambda \neq 0,\\
      \log \bm \mu, & \lambda=0.
    \end{array} \right .$$
指数函数联接的例子有：
$\bm \eta= \bm \mu^{2};\bm \eta= 1/ \bm \mu;\bm\eta= \sqrt{\bm \mu}$
和 $\bm \eta= \log(\bm \mu)$，即log联接是指数函数联
接的特殊情况。这些都属于Box-Cox型变换。当$\lambda \neq 0$，指数函数联接
逆函数为$\bm \mu =e^{\frac{\ln (\lambda \bm
    \eta+1)}{\lambda}}$。当$\lambda = 0$，逆函数为$\bm \mu= e^{\bm
  \eta}$。

联接函数可以把一些看起来不具有线性结构的模型转化为线性模型。例如，当分别
采用logit和互补log-log联接时，Logistic和Gomperz增长曲线可以转化为线性
模型。

#### 线性预测子

广义线性模型中的线性预测子 $\bm \eta= \bm{X\beta}$ 和经典线性模型中是相
同的。用 $p\times 1$ 维向量 $\bm x_{i}$ 表示第 $i$ 个单位的 $p$ 个自变量观测值
即 $\bm x_{i}=[x_{i1},\cdots, x_{ip}]^{T}$ ， $\bm \beta$ 是 $p \times 1$ 维
参数向量，即 $\bm \beta=[\beta_{1}, \cdots, \beta_{p}]^{T}$ 。所有
的 $\bm x_{i}^{T}, i=1,\cdots,n$ 按行拼接成 $n\times p$ 阶矩阵 $\bm X$ ，即
$$\bm X= \left [
    \begin{array}{cccc}
      x_{11}& x_{12}& \ldots & x_{1p}\\
      x_{21}& x_{22}& \ldots & x_{2p}\\
      \vdots& \vdots& \ddots & \vdots\\
      x_{n1}& x_{n2} & \ldots & x_{np}
    \end{array}
  \right].$$ 

$\bm X$被称为**设计矩阵**。

## 非参数回归和广义可加模型(GAM)

变量之间的关系不一定总是线性的，在许多情况下是非线性的。光滑方法和非参数回归一般
是可以交换的术语，二者都是指一系列对散点图中二元变量关系进行概括的统计方法。使用
更常见的参数统计方法，两个变量 $x$ 和 $y$ 之间的关系可以用像回归或相关系数等参数模
型来进行概括。使用非参数回归，不存在任何参数，而是用一条曲线来概括 $x$ 与 $y$ 之间
的统计关系，考虑到统计模型没有产生任何参数，我们通常把这类模型称为非参数模型。

假设有两个连续变量 $x$ 和 $y$ ，我们希望估计给定 $x$ 时 $y$ 的期望值。这个关系
可以表示为 
$$
  y_{i}|x=f(x)+\varepsilon_{i},$${#eq:old-1-1}
其中$f$ 表示$y$ 与$x$之间关系的函数形式，$f$的限制条件是 $f$ 为光滑函数。熟悉的线 性方程形式是这种类型函数的一种特殊情形： 
$$
  f(x)=\alpha+\beta x$${#eq:old-1-2}
  
线性关系也可以看作是光滑函数的特殊情况。线性回归模型是参数模型，因为参数$\beta$
概括了$x$ 与$y$之间的统计依赖性。如果我们使用非参数回归模型，将不存在参数，这时
需要的假设条件更少。在线性回归模型中，我们假设$f$为线性的，我们继续来估计$\hat
\beta$。然而$f$可能为线性的，$f$也可能为非线性的。当使用非参数回归时，我们利用数
据来估计$f$的函数形式。所以，事先的线性假设被更弱的假设即任意光滑总体函数所代替。
这个更弱的假设的代价是两方面的：第一，计算方面的代价是巨大的，但考虑到现代计算技
术的速度，这不再是很大的问题；第二，光滑函数的可解释性比线性函数差，虽然丧失了一
些可解释性，但得到的回归方程是一个更具代表性的估计。光滑函数$f$的估计方法很多，下
面就介绍几种常见光滑方法。

### 常见光滑方法
#### 核光滑
最简单的光滑方法是使用 $y$的均值作为局部估计，但是简单均值作为局部估计具有严重的缺
陷。非参数回归的目的是得到忠于 $x$与 $y$之间局部关系的估计。但简单均值无论离关注
点的距离如何，都赋予 $x$和 $y$的值以相等的权重。不考虑观测值与关注点之间的距离而
赋予所有的观测值以相同的权重是不合理的。如果我们赋予靠近关注点的观测值更大的权重，
而赋予靠近边界处的观测点以更小的权重，就可以得到一个更忠于$y$ 与 $x$之间局部
关系的非参数估计量。

核光滑非参数回归模型通过使用加权平均重新定义了移动平均光滑方法。我们所
需要的是一个函数，它可以给靠近关注点的数据比远离关注点的观测值以更大的
权重。在考虑加权均值的形式之前，我们需要找到一个测量观测值与关注点距离
的方法。我们将使用这个距离的测度值在加权平均中赋权。一个常见的距离测度
为 
$$\label{eq:6}
  z_{i}=\frac{(x_{i}-x_{0})}{h}.$$
$z_{i}$测量了相对的、正负的第$i$个观测值与关注点$x_{0}$之间的距离。调
正因子$h$称为核估计的带宽，它控制了窗宽，也就控制了非参数估计的光滑或
粗糙程度。

我们现在需要一个函数来赋予数据实际的权重。我们把权重函数称为核函数：
$K(z)$。核函数把最大的权重赋给离关注点$x_{0}$最近的点，也就是$z_{i}$值
小的观测值。随着$|z|$值的增大，此函数光滑对称的给予较小的权重。核函数
以$z_{i}$为自变量来计算每个观测值的权重，然后用于计算局部加权均值。在
每一个窗内把核函数$K$应用到正负的、相对的距离就得到每个窗的权重集合：
$$\label{eq:7}
  w_{i}=K[(x_{i}-x_{0})/h].$$ 权重$w_{i}$用于计算局部加权平均数：
$$\label{eq:8}
  \hat f(x_{0})=\frac{\sum_{i=1}^{n}w_{i}y_{i}}{\sum_{i=1}^{n}w_{i}}.$$

原则上，存在许多不同的核函数可以用于计算局部平均中的权重。不管核函数的
形式是什么，它必须具有一定的性质。首先，核函数必须是关于关注点对称的。
其次，权重必须是正的，并且我们希望权重从关注点到窗的边界光滑的下降。有
许多不同的函数满足这些要求，但最常用的核是三次立方(tricube)核：
$$\label{eq:9}
  K_{T}(z)=\left\{
    \begin{array}{lr}
      (1-|z|^{3})^{3}&\text{当} |z|<1,\\
      0&\text{当} |z|\geq 1.
    \end{array}\right.$$
三次立方核的一个优点就是其计算简单。在早期光滑方法应用中，这是它被推荐
的主要原因。现在，虽然计算问题影响不大，但这个核仍然被广泛使用。另一个
经常使用到的核是正态核，它是把标准正态分布的密度函数应用到$z_{i}$的值上
面： 
$$\label{eq:10}
  K_{N}(z)=\frac{1}{\sqrt{2\pi}}e^{-z^{2}/2}.$$
使用三次立方核和正态核得到的非参数估计的差异一般可以忽略。注意到实际上
简单移动平均也是一个核光滑器。简单移动平均光滑器具有一个矩形核。对于矩
形核，我们给予窗中的每一个观测值以相等的权重，也就产生了一个没有加权的
局部平均值。矩形核为 
$$\label{eq:11}
  K_{R}(z)=\left \{
  \begin{array}{lr}
    1&\text{当} |z|<1,\\
    0&\text{当} |z|\geq 1.
  \end{array}\right.$$
尽管核光滑器相对于简单移动平均估计来说是一个改进，但其仍然存在一定的缺
点。核光滑器的主要缺点在于：无论是加权的还是没加权的均值，都不是一个最
优的局部估计量。下面介绍的局部回归估计就可以得到一个更优的非参数回归模型。
	
#### 局部回归光滑器
替代均值作为局部估计量的一个显然的办法就是使用最小二乘估计。实际上，许
多广泛使用的非参数回归模型都是基于局部回归估计而不是局部平均估计，因为
回归具有均值所不具有的偏倚缩减性质。非参数回归估计的基本算法几乎仍然与
核光滑是一样的。我们构建一系列由研究者确定宽度的窗。在每个窗内，进行 $y$
对$x$的回归，局部估计就是在关注点$x_{0}$处的预测值。在每个窗内重复这个
过程，然后把每个预测值连接起来就得到了$f$的非参数估计。

Cleveland(1979)首先提出局部回归光滑器，大部分统计软件包使用他提出的算法。
他提出的局部回归方法**loess**及其变种**lowess**是使用最多的非
参数回归模型之一[@cleveland1979robust]。前者是**local regression**的简称，
后者是 **local weighted regression**的简称。这两种光滑器在几个方面都比
目前为止介绍的局部回归思想复杂。下面对Cleveland的非参数回归模型进行讨
论。

Cleveland提出了一个多项式回归模型而不是线性回归的局部估
计[@cleveland1979robust]。预测变量$x$的 $p$阶多项式回归为 
$$
  y=\alpha+\beta_{1}x+\beta_{2}x^{2}+\cdots+\beta_{p}x^{p}+\varepsilon.$${#eq:old-1-12}
如果$p=1$ ,那么拟合是线性的，如果$p=2$那么拟合是抛物线，等等。多项式阶数
的选择可以根据研究的需要，但一般高于2阶的多项式对于提高非参数估计的表
现作用有限。

下面的递归拟合过程得到非参数回归估计量：

首先，对于窗中的每一个$x$的观测值都计算出权重。计算方法与前面介绍的核光
滑的权重计算方法相同。Cleveland推荐使用三次立 方核。

其次，在窗内使用权重为$w_{i}$的加权最小二乘估计拟合局部多项式回归模型。
具体地，我们估计下面的局部回归模型： 
$$\frac{y_{i}}{w_{i}}=
  \alpha+\beta_{1}\frac{x_{i}}{w_{i}}+\beta_{2}\frac{x_{1}^{2}}{w_{i}}+\cdots
  +\beta_{p}\frac{x_{i}^{p}}{w_{i}}+\frac{\varepsilon_{i}}{w_{i}},$${#eq:old-1-13}
  
可以通过最小化加权残差平方和$\sum_{i=1}^{n}w_{i}e_{i}^{2}$来得到参数的
估计值。尽管一般使用三次立方核，但其它权重也是可能的。在最初的加权最小
二乘拟合后，基于局部拟合的残差的新的具有稳健性的权重就可以计算出来。将
具有较大残差的观测值赋予较小的权重，具有较小残差的观测值赋予较大的权重。
这些稳健性权重为 
$$\label{eq:14}
  \delta_{k}=B(e_{k}/6s),$$
其中$e_{k}$是局部残差，$s$是 $|e_{k}|$的中位数， $B$是双二乘(bisquare)核
函数，其与三次立方核除了使用二阶多项式之外，其它都是相同的。基于这些新
的权重，可以再次进行局部加权拟合，重复这个过程，直到局部估计的变化幅度
小于定义的容忍水平。

最后，计算出在关注点$x_{0}$ 处$y$的拟合值。在每一个窗内重复这个过程，得
到每一个窗的拟合值，然后把这些拟合值用线段连接起来最后得到非参数回归估
计。

局部回归程序没有权重时也可以进行。实际上，有无权重就是**loess**和
**lowess**的区别。这两者之间的区别在实际使用中一般很小。

局部多项式回归中带宽的选择仍然是重要的。界定带宽的方法不是通过定义在关
注点两侧观测值的个数来确定，而是通过窗中包含的观测值的个数占总数据点个
数的比例来确定。这个比例一般称为局部回归光滑器的**幅度(span)**，一
般用$s$来表示。每一个窗中包含的观测值的个数就为$m=[sn]$。

从统计性质上讲，局部回归模型要优于局部平均光滑。Fan and
Gijbels(1992)和Fan(1993)展示了局部线性拟合具有一些局部平均所不具有的非
常好的性质[@fan1992variable; @fan1993local]。他们证明了与局部平均非
参数回归相比，局部多项式回归拟合可以缩减 $\hat f$的偏倚。局部多项式回归
的偏倚缩减性质在边界处表现的最为明显，而核估计量在边界处趋于使非参数拟
合变平。

#### 样条光滑 {#sec:splines}
样条光滑器是另一种用于散点图的非参数回归方法。样条相对于局部多项式回归来说有几个
优点。首先，样条回归具有优于局部多项式回归的分析基础，因为可以证明样条光滑器是最
优均方误差拟合。第二，光滑样条可以防止过拟合，而过拟合是非参数光滑器的主要关注点
之一。第三，估计样条的方法研究仍然比较活跃，而局部多项式回归的研究进展相对静止。
因此，软件中拟合样条模型的方法要优于局部回归的方法。例如，大部分样条实现方法都可
以产生估计的置信带，而局部多项式回归光滑器则不一定。最后，样条更容易集成到半参数
估计中去，他们是许多半参数回归模型中选择的光滑方法。

样条这个名词起源于制图者用于画曲线的一种工具。样条是在称之为“**节点**”的点处连
接的分段回归函数。关于样条的详细讨论可以参见 De Boor(2001)[@de1978practical]。最
简单形式的样条就是在模型右边含有哑变量的回归模型，我们使用哑变量使回归线在 $X$的
范围内一些点处改变方向。对于最简单的回归样条，分段函数是线性的，后面我们将放松这
个限制。本质上，我们在节点之间的区域内分别拟合回归线，节点将分段回归拟合连接在一
起。样条也是允许我们从数据估计函数形式的局部模型，只不过这时是位于节点之间而不是
窗内的局部模型。与局部多项式回归一样，对于样条我们也必须进行模型决策。对于局部多
项式回归，我们必须选择多项式的阶数，带宽，和权重方程等因素。对于样条，我们必须决
定分段回归函数的多项式阶数，节点的个数和节点的位置等因素。

样条的类型非常多。例如：有回归样条，立方样条，B-样条，P-样条，自然样条，
薄板样条和光滑样条等等。样条的广泛性部分来源于样条的研究进程。通常一种
新类型的样条不是取代了旧类型的样条就是对已存在的方法进行了改进。统计中
最常使用的样条是光滑样条。尽管光滑样条比回归样条更复杂，但他们原理基本
相同。

#### 非参数光滑方法比较 {#sec:compar-and-conclude}
目前为止，我们已经介绍了几种不同的非参数回归模型。下面对这些模型进行简单比较。一
个常见的问题是某一种非参数回归方法是否优于其它方法。对于许多实际问题来说，没有哪
一种方法完全优于另一种方法，但光滑样条方法确实具有一些优点。它是唯一对在拟合中使
用的参数施加惩罚项的光滑器。非参数回归的主要不足之一就是其易于过拟合数据，光滑样
条直接面对这个不足的并加以解决。而且，光滑样条的混合模型框架为这些光滑器提供了一
个分析基础。

提供一些模拟的证据来展示不同的光滑器对一个高度非线性函数形式的拟合效果。在这个模
拟中，我们产生一个函数$f$并使用4个不同的光滑器进行拟合，分别为两个局部多项式拟合，两个
样条光滑器来对模拟的数据进行拟合。这个非线性方程为： 
$$y=\sin^{3}(2\pi x^{2})+\varepsilon.$${#eq:old-1-60}
  
其图形呈现周期样式。这种形式的函数在实际中非常罕见，但对于非参数回归来说，是难
以估计的。图 \@ref(fig:fig-nonpara-compare) 给出了这4个非参数拟合，其中虚线代表真实函数形式，实线代表非参数估计。

```{r fig-nonpara-compare, eval=T, fig.height=6, fig.width=6.5, out.width="1.05\\textwidth", fig.pos="h", fig.cap = "4种光滑方法拟合的比较", dev=c("cairo_pdf"), dev.args=list(family="Microsoft YaHei UI Light")}

library(SemiPar)
library(splines)

#Comparison Plots
#Simulate A Very Wavy Functional Form
trans<-function(x) {sin(2*pi*x^2)^3}
x<-seq(0,2,by=.01)
y<-trans(x)+.2*rnorm(201)

loess <- loess(y ~ x, span=0.1)

#Loess- Must adjust span to almost minimum
xhatloess <- x
yhatloess <- fitted(loess)

#Figure 3.11
#Black Line Represents Estimated Smoothed Fit
par(mfrow = c(2,2))

#Loess
matplot(x, cbind(y, trans(x)),
    type="pl", lty=2, col=1, pch="",
   xlab="X", ylab="Y", main = "Loess", bty = "l")
lines(xhatloess, yhatloess, lwd=1)

#Cubic B-spline
matplot(x, cbind(y, trans(x)),
   pch="", type="pl", lty=2, col=1,
   xlab="X", ylab="Y", main = "自然立方B样条", bty = "l")
sp1<-lm(y~ns(x, df=15))
lines(x,sp1$fit, lwd=1)

#Lowess
matplot(x, cbind(y, trans(x)),
   pch="", type="pl", lty=2, col=1,
   xlab="X", ylab="Y", main="Lowess", bty = "l")
lines(lowess(x,y, f = 0.05), lwd=1)

#Smoothing Spline
matplot(x, cbind(y, trans(x)),
   pch="", type="pl", lty=2, col=1,
   xlab="X", ylab="Y", main="光滑样条", bty = "l")
fit <- spm(y ~ f(x))
lines(fit, se=FALSE, lwd=1)

```

第一个非参数模型是Loess局部回归光滑器。采用目测试错方法，选取0.1作为带宽值。拟合效果不错
但存在一些欠光滑，因为它缺失了一些峰和谷。右上角的图是使用AIC准则选择节点的自然
三次B样条拟合。这个模型中显示了明显的欠光滑，在$x$的后半部分拟合效果较差。左下角
图中是Lowess局部回归估计。Loess估计与Lowess估计几乎是完全相同的，因此我们再次发现使用的权重对于估计几乎
没有什么作用。最后使用目测试错方法选择自由度为31的光滑样条估计。光滑样条估计
很好的拟合了非线性，只有轻微的欠光滑出现。光滑样条的表现与两个局部多项式回归相类
似。模拟显示光滑样条和两个局部多项式都是不错的选择。对于基本的散点图光滑来说，没
有什么理由偏好于哪一种非参数回归方法。只有在比较罕见的情况下，不同的光滑方法才会
导致不同的拟合结果。在下一节我们将看到，还有其它的原因偏向于光滑样条模型。而且，
对于半参数回归模型来说，光滑样条也是更好的选择。

光滑器本身只能作为强大的诊断工具。在实际研究中很少单独使用非参数回归本身进行建模。
然而，非参数方法对于检验两个变量之间是否具有非线性关系特别有用。不使用光滑器仅凭
目测很难得到两个变量之间的关系。我们将看到，光滑器与标准的参数模型结合使用将是更
为强大的统计建模工具。

### 多元非参数回归 {#sec:multi-nonpara-reg}
上面我们介绍了几种非参数回归模型。这些模型的一个优点就是它们在不对函数形式做假设
时就允许对变量 $x$ 和 $y$ 之间的关系进行估计。然而，对于自变量个数超过2个的多维
情况，非参数回归就难以应用。因此这严重限制了非参数回归在应用领域的作用。而在实际
统计建模过程中遇到更多的情况是自变量的个数较多。如果对于多元情况无能为力，那么非
参数回归在实际应用过程中很难发挥作用。在这种情况下非参数回归仅仅只能作为在进行多
元分析之前的一个探索性分析工具。然而，只要增加一些条件，我们就能把非参数回归增加
到在实际建模中应用极为广泛的标准多元模型中去。如果我们假设自变量对因变量的作用是
可加的，那么我们就可以得到一个部分自变量以参数形式进入而另一部分自变量以非参数形
式进入的半参数回归模型。半参数回归模型可以在熟悉的多元回归模型背景下估计带有非线
性估计的标准参数模型，非参数项可以用于连续自变量或用于非线性的检验。

下面我们讨论半参数回归模型和广义可加模型。我们首先从讨论多元非参数回归和可加模型
开始。可加模型不是半参数模型，但其为半参数回归模型提供了基础。接着我们给出了半参
数回归模型的模型设定，并对半参数回归模型的估计和推断方法进行了讨论。有了可加模型
和广义线性模型基础，得出广义可加模型是自然的。

前面我们主要关注的是两个变量，即一个因变量和一个自变量关系，没有涉及到多个自变量。
但是在大部分应用研究中需要考虑多元模型。局部多项式非参数回归模型可以推广到多元框
架下。一般地，我们可以假设$k$元非参数回归模型为：
$$Y=f(X_{1},\cdots,X_{k})+\varepsilon.$${#eq:semipara-72}

这个模型的估计与一个自变量的非参数回归模型相类似。这时，局部估计使用多
元局部多项式回归而不是一元局部多项式回归。像以前一样，靠近关注点的数据
比远离关注点的数据得到更多的权重。但由于窗的大小变成了平面的距离从而使
得局部窗宽的定义更为复杂。用来自多元局部多项式回归模型的预测值作为局部
估计，把其连接起来就得到了估计的曲面，这个曲面表示
了$x_{1}$和$x_{2}$对$y$的交互作用。二元非参数回归模型等价于非线性交互
模型的设定，其得到的估计是代表两个自变量对$y$的联合作用的曲面。

在这种形式中，有人可能会认为非参数回归适合于标准的多元条件，因此可以在实际建模过
程中使用。但这个模型有两个严重的局限性。第一个问题就是“维数灾难”(curse of
dimensionality)。当模型中自变量的个数增加时，在每个关注点的局部临近区域内的观测
值的个数下降的很快。因此对于固定容量的点来说，当维度增加时，局部临域中用于估计的
点越来越少。一个解决方法就是增加带宽，但增加带宽增加了估计中的偏倚。第二，当自变
量个数多于2个时，解释将变得不可能。当 $k$ 等于2时公式 的结果可以用一个三维曲线来表
示，其表示了这两个变量的联合效应。加入第3个自变量尽管估计是可行的，但要解释得到
的结果就需要额外的维度，而这是不可能的。这些模型不产生任何参数，当模型中包含的自
变量的个数多于两个时，估计的已不可能用图形来显示。多元光滑方法的详细介绍可以参见
Wood(2006)[@wood2006generalized]。

在探讨将非参数回归推广到多个自变量的方法之前。我们先给出多元非参数模型
的分类，如图所示 \@ref(fig:fig-multi-nonpara) 。

```{r fig-multi-nonpara, eval=T, fig.height=5, fig.width=6.5, out.width="1.05\\textwidth", fig.pos="h", fig.cap = "多元非参数回归的分类", dev=c("cairo_pdf"), dev.args=list(family="Microsoft YaHei UI Light")}
par(mfcol=c(2,3),mar=c(2,2.5,2,3))

#------------Linear--------------
pts <- seq (from=0,to=1,len=20)
fff<- function (x,y) { x + y}
rmat <- outer (pts,pts,fff)
info.p <- persp (x=pts,y=pts,rmat,xlab="x2", ylab="x1",zlab="",lwd=1, phi=15, theta=-30, r=10)
title ("参数线性模型")


#-------------Partial Linear--------------------
pts <- seq (from=0,to=1,len=20)
fff<- function (x,y) { x + exp(-15*(y-.5)^2)}
rmat <- outer (pts,pts,fff)
info.p <- persp (x=pts,y=pts,rmat,xlab="z", ylab="x",zlab="",lwd=1, phi=15, theta=-30, r=10)
title ("部分线性模型" )



#-------------Partial Parametric--------------------
pts <- seq (from=0,to=1,len=20)
fff<- function (x,y) { 3*(x-.5)^2 + exp(-15*(y-.5)^2)}
rmat <- outer (pts,pts,fff)
info.p <- persp (x=pts,y=pts,rmat,xlab="z", ylab="x",zlab="",lwd=1, phi=15, theta=-30, r=10)
title ("部分参数模型" )



#------------Additively Separable------------------
pts <- seq (from=0,to=1,len=20)
fff<- function (x,y) { exp(-15*(x-.5)^2) + exp(-15*(y-.5)^2)}
rmat <- outer (pts,pts,fff)
info.p <- persp (x=pts,y=pts,rmat,xlab="xb", ylab="xa",zlab="",lwd=1, phi=30, theta=-45, r=10, d=10)
title ("独立可加模型",cex=.5)


#------------Index Model------------------
pts <- seq (from=0,to=1,len=20)
fff<- function (x,y) { sin((x+y)*5)}
rmat <- outer (pts,pts,fff)
info.p <- persp (x=pts,y=pts,rmat,xlab="x2", ylab="x1",zlab="",lwd=1, phi=30, theta=-45, r=10, d=10)
title ("单指标模型")

#----------------Nonparametric-------------------
pts <- seq (from=0,to=1,len=20)
#fff<- function (x,y) { exp(-15*(x-.5)^2) * exp(-15*(y-.5)^2)}
fff<- function (x,y){(sin(10*x)-cos(5*y))* exp(-15*(x-.5)^2) * exp(-15*(y-.5)^2)}
rmat <- outer (pts,pts,fff)
info.p <- persp (x=pts,y=pts,rmat,xlab="x2", ylab="x1",zlab="",lwd=1, phi=30, theta=-45, r=10, d=10)
title ("完全非参数模型")

```

首先考虑完全的非参数模型$y=f(x)+\varepsilon$，其中$\varepsilon$服从独立的
具有0均值和常数方差$\sigma_{\varepsilon}^{2}$的分布。如果仅假设$f$属于光滑函
数族$\mathfrak{F}$，那么此时模型是非参数的，且对其约束条件很少。这个也
就是完全的多元非参数回归模型。图 \@ref(fig:fig-multi-nonpara) 中的两个对角处
给出了完全参数模型和完全非参数模型。

考虑到估计多个自变量的完全非参数模型存在的困难，研究者一般寻求简约的组合
模型。一个例子就是部分线性模型,也就是我们将要讨论的半参数回归模型。
我们从图 \@ref(fig:fig-multi-nonpara) 中可以看到，对于任意固定的$x$，回归函数
是$\bm{z}$的线性函数。部分参数模型是部分线性模型的一个推广，其
中$y=g(\bm{z;\beta})+f(x)+\varepsilon$， $g$是一个已知的函数。对于
图 \@ref(fig:fig-multi-nonpara) 中的部分参数模型曲面，对于任意固定
的$x$值, $g$ 是$z-a$的二次函数。

单指标模型构成了另一种组合。在$y=f(\bm{x\beta})+\varepsilon$的情况下，
对于任意固定的指数值$\bm{x\beta}$，函数$f(\bm{x\beta})$是固定的。
图 \@ref(fig:fig-multi-nonpara) 中描述的指数模型由$y=\cos(x_{1}+x_{2})$给出。
因此，在$x_{1}+x_{2}=$固定值时，函数是平的直线。部分线性指数模型是另一
类推广，即$y=f(\bm{x\beta})+\bm{z\delta}+\varepsilon$。

最后，如果我们可以把$\bm{x}$分为两个子集$\bm{x_{a}}$和$\bm{x_{b}}$，且
$f$可以写为$f_{a}(x_{a})+f_{b}(x_{b})$的形式，那么这个模型成为独立可加
的。(当然，部分线性模型和部分参数模型都是独立可加的，但这时一个部分是
参数的，另一个部分是非参数的。)

我们将讨论上面分类中的部分线性模型(半参数回归模型)和独立可加模型(简称
为可加模型)。

### 可加模型 {#sec:addtive_models}

多元非参数回归模型由于“维数灾难”等局限性导致其难以运用到实际建模过程
中。我们希望能找到既能达到数据降维同时又能保留非参数光滑优点的方法。主要
的方法就是可加模型。

把非参数回归模型推广到两个以上的自变量需要额外的假设：可加。尽管可加
性的条件比完全的多元非参数回归模型具有限制性，但它是统计建模过程中使用
的参数模型中几个最常见的假设之一。对于参数线性回归模型，一般假设其函数
形式为： 
$$Y_{i}=\alpha+\beta_{1}X_{1}+\cdots+\beta_{k}X_{k}+\varepsilon.$${#eq:semipara-73}
在这个函数形式中，我们一般假设自变量对$Y$的作用是可加的：$X_{1}$和
$X_{2}$的作用是$\beta_{1}+\beta_{2}$。可加假设有时候可以放松到含有交
互项的模型： 
$$
  Y=\alpha+\beta_{1}X_{1}+\beta_{2}X_{2}+\beta_{3}X_{1}X_{2}+\varepsilon.$${#eq:semipara-74}
可加条件是相当严格的，但它已经在我们估计的大部分模型中出现，因此我们
可以把它推广到非参数回归模型。具有可加条件的非参数回归模型具有以下形
式： 
$$
  Y_{i}=\alpha+f_{1}(X_{1})+\cdots+f_{k}(X_{k})+\varepsilon$${#eq:semipara-75}
其中$f_{1},\cdots,f_{k}$是任意的光滑函数，我们将用数据通过光滑器进行估
计。具有可加条件的非参数回归模型称为**可加模型**。可加的动
机来源于把非参数回归模型推广到多元数据分析中的愿望(Hastie，
Tibshirani,1990)[@hastie1990generalized]。可加性假设获得了更多的
可解释性，因为这个假设表明了多元非参数回归模型与多元线性回归模型具有相同的可解释性。
尽管可加模型相对于多元非参数回归模型来说具有许多优点，但他们仍然具有
一定的限制，这些限制使得可加模型在实际建模中使用并不多。具体地，可加
性模型缺少一个重要的特征，而这个特征包含在半参数回归模型中。

### 半参数回归模型 {#sec:semipara-reg-model}
如果我们只估计连续变量之间的非线性关系，可加模型刚好适合，但在实际建模过程中自变
量与因变量的关系并不都是非线性关系。首先，离散自变量是非常普遍的，而且个数通常比
连续自变量个数多。第二，有的自变量与因变量之间的关系可能实际上是线性的。如果一个
参数足够描述$X$ 与$Y$之间的关系，就没有必要使用额外的参数来估计非参数回归。总之，
最具灵活性的模型应是在同一个模型中既包含参数项又包含非参数项。我们可以直接修改可
加模型来同时估计参数项和非参数项。混合参数项和非参数项的一个模型可以采取以下形式：
$$
  Y_{i}=\alpha+f_{1}(X_{1})+\cdots+f_{j}(X_{j})+\beta_{1}X_{j+1}+\cdots+\beta_{k}X_{k}+\varepsilon.$${#eq:semipara-77}
  
在上面模型中，前$j$个自变量被认为对$Y$有非线性作用，因此用非参数光滑器进行拟合。
其它的自变量以参数形式进入模型。在可加模型中添加参数项就得到**半参数回归模型**。
半参数回归模型可以估计种类非常多的函数形式。模型中的参数部分允许像哑变量或定序变
量的离散变量与非参数项一起建模。研究者认为对$Y$的作用为线性的连续自变量可以以参
数方式进行估计以节省参数。半参数模型相对于完全的参数模型也具有优势。在半参数框架
下，非参数的推断在半参数回归模型中得到了保留，它允许检验任何一个非参数项对于模型
来说是否需要。半参数回归模型是一个可以同时对变量间线性和非线性依赖关系进行建模的
工具。

### 广义可加模型 {#sec:gener-addit-models}
上面讨论的模型是在线性模型框架下的半参数模型，但我们可以使用半参数来估计各种类型
的回归模型。我们把上面讨论的广义线性模型应用到半参数回归模型中就得到广义可加模型
(Generalized Additive Model, GAM)。下面给出广义可加模型的模型设定。

广义线性模型框架有助于说明为什么具有离散因变量的回归模型也需要半参数方法。在广义
线性模型框架下，模型有三个部分:随机部分，系统部分和连接函数。我们必须根据实际问
题的情况来选择这三个部分。我们必须注意的是：广义线性模型的基本函数形式仍然是线性
可加的。系统部分中的函数形式是线性的，在使用连接函数之后才具有非线性。例如在一个
Probit模型中，Probit模型的系统部分是线性的，在使用正态分布累计函数之后，就把线性
函数转化为一个非线性的概率度量。

我们可以改变系统部分的函数形式以放松线性和可加的假设。可以在函数形式
中增加额外的部分以引入交互项。重要的是，如果真实模型是变量的非线性形式，
那么这个非线性必须在系统部分中建模。连接函数对于自变量的非线性无能为力。例
如，如果系统部分的真实形式为 
$$
  \eta_{i}=\alpha+\beta_{1}X_{1i}+\beta_{2}X_{2i}^{2}.$${#eq:semipara-93}
无论使用什么样的连接函数，二次项都必须在系统部分中引入。因此，如果系统
部分使用线性函数，一些非线性将不能被拟合，此时，模型中仍存在设计误差，
尽管它们是非线性模型。实际上，在GLM框架中对于大多数模型来说，设计误差变
得更为严重。在线性回归模型中，设计误差仅仅影响相关的自变量。但对于许多
具有非线性连接函数的GLM模型来说，不相关的变量也会影响设计误差，从而影响
估计(Yatchew，Griliches, 1985)[@yatchew1985specification]。因此，
无论选择何种连接函数，GLM模型系统部分中的非线性仍然没有办法消除。这时，
非参数方法可以对GLM中系统部分的非线性进行建模。这就得到广义可加模
型(GAM)，正与可加模型扩展了线性模型一样，GAM扩展了GLM。

为了设定GAM，我们允许GLM中系统部分的线性函数变为一些来自自变量的光滑函
数。一般地，广义可加模型具有以下形式： 
$$g(\mu_{i})=\bm{X\beta}+f_{1}(x_{1i}) + f_{2}(x_{2i}) + \cdots $${#eq:semipara-gam} 
其中
$$\mu_{i} = \mathbb{E}(Y_{i}),\text{并且~} Y_{i}
  \overset{\text{i.i.d}}{\sim} \text{~指数分布簇中某一分布.}$$
$Y_{i}$是因变量，$\bm X$是设计矩阵，$\bm \beta$是对应的参数向量，
$f_{j}(\cdot)$是自变量$x_{k}$的光滑函数。

使用GAM，我们仍然可以使用假设检验来检验非参数回归对线性拟合或对幂转换拟合。像可
加模型一样，GAM中如果不包括参数项，那么其作用有限，而且加入参数项并不困难。上面
的半参数回归模型可以扩展到离散数据模型。对离散数据建模的半参数方法为诊断和拟合非
线性提供了一套灵活的框架。尽管GAM实质上不是半参数回归模型，但GAM这个术语经常应用
到半参数GLM中。在下面的讨论中，我们采取这个约定。因此，术语GAM同时包括可加GLM和
半参数GLM。

GLM的估计可以使用Newton-Raphson算法的直接最大似然估计法或迭代再加权最小二乘法
(Iteratively Reweighted Least Squares, IRLS)(Hardin，Hilbe,2007)得到[@hardin2007generalized]，具体可以参考Hardin，
Helbe(2007)给出的一个关于每种算法的概述。IRLS更适合于GAM的估计，因为它把GLM的估
计减少化到加权最小二乘的迭代应用。我们可以使用backfitting算法来估计GAM中系统部分的
光滑函数。基于样条混合模型的GAM采用了Newton-Raphson方法，详细参见Ruppert，Wand，
Carrol(2003)对这个估计程序的介绍[@ruppert2003semiparametric]。关于用于估计GAM的
IRLS算法的基本步骤，详细可以参 考Hastie，Tibshirani(1990)和Wood(2006)的著作
[@hastie1990generalized; @wood2006generalized]。

IRLS方法的优点是其估计GAM并没有比估计一个可加模型困难多少，而GAM模型的估计明显比
可加模型的计算强度更大。在可加模型里面，我们仅需要运行一次backfitting算法，而在
GAM里面，在IRLS的每一次迭代过程中，我们都必须估计一个可加模型。在现代计算机上一
般估计GAM会稍微慢一点，对于大数据集来说，估计GAM等待的时间可能会更长。

我们将前面讨论的光滑方法和非参数回归模型应用到GLM就可以得到GAM。在使用广义可加模
型时，一个值得注意的问题是非参数估计比参数估计需要更多的数据。GAM有时候不能收敛，
而这在GLM中则不存在。尽管收敛失败不常见但有可能发生。一旦收敛失败，那么我们必须
依靠完全参数模型。

与单一的非参数回归模型不同，半参数模型和广义可加模型在实际建模过程发挥了巨大的作
用。但是，半参数模型和广义可加模型仍只能适用于独立数据建模。对于相关数据，半参数
模型和广义可加模型无能为力。混合模型是处理相关数据的有力工具，因此下面我们将讨论
半参数混合模型和广义可加混合模型。

## 线性混合模型和广义线性混合模型(GLMM) {#sec:lme}
混合效应模型是分析分组数据的灵活、强大的工具。分组数据在许多领域中广泛存在，例如
农业、生物、经济、制造业和地质学。纵向数据、重复测量数据，多水平数据、层次数据等
都属于分组数据。经典线性模型中一个典型的假设就是观测值来自一个相同的总体，即是独
立同分布的。而一般分组数据的组内观测值是相关的，因为它们属于相同的子总体，而组间
是独立的。混合效应模型可以对分组数据中存在的组内相关进行建模，并且为平衡数据和非
平衡数据提供了统一的分析框架。混合效应模型是非线性统计模型，主要是因为其具有复杂
的方差结构。混合效应模型的出现把线性模型带入了一个更广阔的空间。从混合效应模型的
理论发展过程来看，最开始讨论的是线性混合效应模型，然后又发展到广义线性混合效应模
型。

### 线性混合模型
线性混合模型在生物、医学、经济、金融、环境保护、工业设计等领域都具有广泛应用。但
是,在不同的领域有一些特殊的模型。混合效应模型的理论起源较多，根据应用领域、模型
用途和强调的侧重点不同，不同领域中有不同的称呼。在社会学研究中，它经常被称为多层
次模型(multilevel models)或分层模型(hierarchical models)；在生物统计研究中则有增
长曲线模型；计量经济学文献称之为随机系数模型 (random coefficient models)和面板数
据模型。

除了用于分组数据建模外，混合效应模型对理解其他一些统计方法也有重要作用。混合
模型的作用非常广泛，Demidenko(2004)指出混合效应模型可以用于以下目的
[@demidenko2004mixed]：拟合复杂的相关数据，包括纵向数据，分层数据、空间数据等；
拟合具有多变异性的数据；拟合异方差数据；作为频率方法和贝叶斯方法的折衷方法；作为
罚似然统计模型；处理参数多维性。

混合效应模型像其他统计模型一样，是用来描述一个因变量和多个自变量之间的关系。在混
合效应模型中，至少有一个自变量是分类变量，其用来代表数据中实验或观测的单位。分类
变量可以取离散水平值。与自变量水平相关联的参数有时候也被称为水平的效应。如果变量
水平的取值是固定并且是可复制的，那么用**固定效应**参数来对这个自变量建模。如果观
测到的水平值代表了该自变量所有可能取值水平的一个样本，我们则在模型中加入**随机效应**。

区分固定效应参数和随机效应需要注意两点：第一，这两个名字具有误导性，因为固定和随
机的区分更多的是针对分类自变量取值水平的性质，而不是与水平相关联的效应的性质。第
二，注意区分“固定效应参数”和“随机效应”的本质。固定效应参数就是我们在统计模型
中碰到的普通意义上的参数。而随机效应严格来讲，并不能算参数，实际其为未观测到的随
机变量。

从前面的叙述我们看到，混合模型包括一大类模型，适用于各种类型的相关数据。下面就以
纵向数据为例给出线性混合模型的模型设定。纵向数据研究一般是考查对个体单位重复测
量的特征随时间的变化规律。每个个体单位在不同的时间点，甚至不同的外界条件下进行重
复观测。通常，我们不能控制观测时的外界条件，并且被观测的个体数量和观测时间可能发
生较大变化。纵向数据通常难以用未限制协方差结构的普通多元模型分析，而混合模型是分
析纵向数据的有力工具。纵向数据混合模型的研究最先由Laird，Ware(1982)年的一篇论文
中给出[@laird1982random]。

线性混合模型可以表示成 
$$\begin{aligned}
  \label{eq:13}
  y_{ij}=&\beta_{1}x_{1ij}+\cdots+\beta_{p}x_{pij}
  +b_{i1}z_{1ij}+\cdots+b_{iq}z_{qij}+\varepsilon_{ij} \\
  b_{ik}\thicksim& \mathcal{N}(0,\sigma^{2}\psi_{k}^{2}),
  \text{Cov}(b_{k},b_{k'})=\sigma^{2}\psi_{kk'} \nonumber \\
  \varepsilon_{ij} \thicksim &\mathcal{N}(0,\sigma^{2}\lambda_{ijj}),
  \text{Cov}(\varepsilon_{ij},\varepsilon_{ij'})
  =\sigma^{2}\lambda_{ijj'} \nonumber\end{aligned}$$
其中$y_{ij}$表示所有$M$组中第$i$组，该组中所有$n_{i}$观测值中的
第$j$个。$\beta_{i},\cdots,\beta_{p}$是固定效应参数，对所有组都是相同
的。$x_{1ij},\cdots,x_{pij}$表示$p$个固定效应回归子第$i$组第$j$个观测值；
第一个回归子通常取常数，即$x_{1ij}=1$。$b_{i1},\cdots,b_{iq}$是第$i$组
的随机效应，假设其服从多元正态分布。随机效应随着组的不同而不
同。$b_{ik}$被认为是随机变量，而不是参数，在这个意义上，其与误差
项$\varepsilon_{ij}$相类似。$z_{1ij},\cdots,z_{qij}$是随机效应回归
子。$\sigma^{2}\psi_{k}^{2}$是随机效应的方差，$\sigma^{2}\psi_{kk'}$是
随机效应的协方差，随机效应方差和协方差被假定为是常数，不随着组的不同而
不同。在一些应用中，这些$\psi$的值可以用一些相对较少的基本参数来表
示。$\varepsilon_{ij}$是组$i$第$j$个观测值的误差项。第$i$组的误差项被假
定服从多元正态分布。$\sigma^{2}\lambda_{ijj'}$是第$i$组误差项之间的协方
差。通常$\lambda_{ijj'}$可以用一些基本参数对其进行参数化，它们的具体形
式依赖于具体问题。例如，当观测值是在组内独立抽样时，这时假定具有不变的
误差项方差，$\lambda_{ijj}=1,\lambda_{ijj'}=0(\text{当}j\neq
j'\text{时})$，此时唯一需要估计的参数就是相同的误差项方差$\sigma^{2}$。
当组内的观测值表示来自同一个个体的纵向数据时，此时$\lambda$的结构必须设
定为可以体现误差项之间自相关关系。

将模型改写成矩阵形式有 
$$\begin{aligned}
  \label{eq:14}
  \boldsymbol{y_{i}}=&\boldsymbol{X_{i}\beta+Z_{i}b_{i}+\varepsilon_{i}}, \quad
  i=1,\cdots , M,\\
  \boldsymbol{b_{i}}\thicksim&\boldsymbol{\mathcal{N}}(\boldsymbol 0,\sigma^{2} \boldsymbol \Psi)\nonumber\\
  \boldsymbol{\varepsilon_{i}}\thicksim&\boldsymbol{\mathcal{N}}(\boldsymbol 0,\sigma^{2} \boldsymbol \Lambda_{i})\nonumber\end{aligned}$$
其中 $\boldsymbol{y_{i}}$是第$i$组观测值的$n_{i}\times 1$因变量向量。
$\boldsymbol{X_{i}}$是第$i$组观测值的固定效应$n_{i}\times p$模型矩阵。
$\boldsymbol{\beta}$是固定效应系数的$p\times 1$向量。
$\boldsymbol{Z_{i}}$是第$i$组观测值的随机效应$n_{i}\times q$维模型矩阵。
$\boldsymbol{b_{i}}$是第$i$组随机效应$q\times 1$向量。
$\boldsymbol{\varepsilon_{i}}$是第$i$组观测值的误差项$n_{i}\times 1$向量。
$\sigma^{2}\boldsymbol{\Psi}$是随机效应的$q\times q$协方差矩阵。
$\sigma^{2}\boldsymbol{\Lambda_{i}}$是第$i$组误差项的$n_{i}\times n_{i}$
协方差矩阵。

上式中的$M$个等式可以表示成一个更浓缩的形式 
$$\boldsymbol{y=X\beta+Zb+\varepsilon},$${#eq:15}
其中 
$$\label{eq:16}
  \boldsymbol{y=}
     \left [
      \begin{array}{c}
        \boldsymbol y_{1}\\
        \boldsymbol y_{2}\\
        \boldsymbol \vdots \\
        \boldsymbol y_{M}
      \end{array}\right ],
    \boldsymbol{X=}
     \left [
      \begin{array}{c}
        \boldsymbol X_{1}\\
        \boldsymbol X_{2}\\
        \boldsymbol \vdots \\
        \boldsymbol X_{M}
      \end{array}\right ],
    \boldsymbol{Z=}
     \left [
      \begin{array}{ccc}
        \boldsymbol Z_{1} & \boldsymbol 0 & \boldsymbol 0\\
        \boldsymbol 0& \boldsymbol \ddots & \boldsymbol 0\\
        \boldsymbol 0& \boldsymbol 0 & \boldsymbol Z_{M}
      \end{array}\right ],
    \boldsymbol{b=}
     \left [
      \begin{array}{c}
        \boldsymbol b_{1}\\
        \boldsymbol b_{2}\\
        \boldsymbol \vdots \\
        \boldsymbol b_{M}
      \end{array}\right ],
    \boldsymbol{\varepsilon=}
     \left [
      \begin{array}{c}
        \boldsymbol \varepsilon_{1}\\
        \boldsymbol \varepsilon_{2}\\
        \boldsymbol \vdots \\
        \boldsymbol \varepsilon_{M}
      \end{array}\right ]$$
分别是$N\times 1, N\times p, N\times Mq, Mq\times 1, N\times 1$阶向量或
矩阵，其中$N=\sum_{i=1}^{M}n_{i}$是所有观测值的个数，$\text{Cov}(\boldsymbol
b)=\sigma^{2}(\boldsymbol{I \otimes \Psi})$， $\text{Cov}(\boldsymbol
\varepsilon)=\sigma^{2}(\boldsymbol{I \otimes \Lambda_{i}})$。

进一步，模型可以写成只包含一个误差项的形式为 
$$\boldsymbol{y=X\beta+\eta},$${#eq:17}
其中 
  $$\boldsymbol \eta= \left[
    \begin{array}{c}
      \boldsymbol \eta_{1}\\
      \boldsymbol \eta_{2}\\
      \boldsymbol \vdots\\
      \boldsymbol \eta_{M}
    \end{array} \right ] =
  \left[
    \begin{array}{c}
      \boldsymbol{\varepsilon_{1}+Z_{1}b_{1}}\\
      \boldsymbol{\varepsilon_{2}+Z_{2}b_{2}}\\
      \boldsymbol \vdots\\
      \boldsymbol{\varepsilon_{M}+Z_{M}b_{M}}
    \end{array} \right ].$$
	
此时， $E[\boldsymbol \eta]=\boldsymbol 0$ ，$\boldsymbol \eta$ 的协方差矩阵为
$N \times N$ 阶块状对角矩阵形式： 
$$\boldsymbol V =\sigma^{2} \left [
    \begin{array}{cccc}
      \boldsymbol{\Lambda_{1}+Z_{1}\Psi Z_{1}^{T}} & \boldsymbol 0 & \boldsymbol 0 &\boldsymbol 0 \\
      \boldsymbol 0 &  \boldsymbol{\Lambda_{2}+Z_{2}\Psi Z_{2}^{T}} & \boldsymbol 0&\boldsymbol 0\\
      \boldsymbol \vdots &\boldsymbol \vdots &\boldsymbol \ddots &\boldsymbol \vdots \\
      \boldsymbol 0 &\boldsymbol 0 &\boldsymbol \ldots &  \boldsymbol{\Lambda_{M}+Z_{M}\Psi Z_{M}^{T}}
    \end{array} \right ].$$ {#eq:m-2.3.1}

上面的设定尽管模型和的形式比简单，但其符号的说明比较复杂。

在随机效应和随机误差项服从正态分布的假设下，混合模型可以表示为因变量的边际分布 
$$\boldsymbol{y \thicksim \mathcal{N}(X\beta,V)},$${#eq:old-20}
其中 $\boldsymbol{V}$为式 [@eq:m-2.3.1] 所定义。


### 半参数模型和混合模型的关系
随机效应是解决统计模型中未观测到的异质性一种常见方法。例如，面板数据模型就容易受
到异质性影响。在面板数据模型中，模型的截距随着数据中的个体而变化，随机效应可以用
于对这些个体截距中的变异性进行建模。在随机效应模型中，一个来自均值为0，方差为
$\sigma^{2}$的正态分布的随机冲击加在每一个个体截距上。这个随机冲击就可以消除异质
性。因此，我们可以使用混合模型来估计样条。实际上，光滑样条刚好可以表示为混合模型
框架中的最优预测量(Ruppert, Wand and Carroll 2003)[@ruppert2003semiparametric]。
尽管混合模型框架对于样条方法在实际数据分析中没有很大作用，但是从混合模型框架的角
度来看待样条方法可以提供两点新理解。第一，混合模型为理解为什么光滑样条是最优光滑
器提供了分析框架。第二，混合模型框架把非线性表示成未观测的异质性，这有助于我们理
解为什么需要非参数回归技术。接下来，我们非常简略地概述混合模型框架并展示如何把光
滑样条表示为混合模型。把样条视为混合模型的详细讨论参见Ruppert, Wand and
Carroll(2003)[@ruppert2003semiparametric]。

在混合模型框架中，对$Y$我们可以写出以下线性回归模型： 
$$
  Y_{ij}=\beta_{0j}+\beta_{1j}X_{ij}+e_{ij}.$${#eq:112}
对于混合模型，一般地模型公式中每一项都有两个下标(或者更多)。在这种记号
中，我们有嵌套在$j$个个体当中的$i$个观测值。这可以是嵌套在$j$个学校中
的$i$个学生。我们认为在不同的$j$个个体之
间具有异质性，也即斜率和截距随着$j$个体的不同而变化。如果我们怀疑在截
距和斜率之间存在这样的变异性，那么一个来自正态分布的随机数就可以按照以
下方式加入到截距和斜率参数中： $$\begin{aligned}
  \label{eq:113}
  \beta_{0j}=\gamma_{00}+u_{0j} \nonumber \\
  \beta_{1j}=\gamma_{10}+u_{1j}\end{aligned}$$
其中$u_{0j}$和 $u_{1j}$都服从$\mathcal{N}(0,\sigma^{2})$ ，是随机效应，
$\gamma_{00}$是$j$个个体的平均结果，$\gamma_{10}$是$j$个个体的平均斜率。
使用ML或者REML估计量，我们对随机效应进行积分以从对数似然函数中移除它们。

混合模型是一种对分组数据进行建模的惩罚方法，它是在简约模型与参数过多模
型的一种折衷。当数据聚集在个体中时，我们可以估计三种统计模型。在第一个
模型中，我们忽略$j$个体中的聚集作用，使用聚合之后的数据估计回归模型。
当$j$个体之间差异很大时，这样得到的聚合模型是有偏的。使用聚合数据，得到
的拟合没有多少变异性，因为这时我们把所有观测值都放在了一起使用。从参数
的个数角度来看，使用聚合数据得到的模型是最简约的模型。另一个极端情况是，
我们可以对$j$个体的每一个个体都估计一个回归模型。这种方法要估计的参数将
很多，当每个个体中包含的观测值个数不大的情况下，参数$\beta$的变异性很大。
然而，这些估计是无偏的。混合模型方法代表了这两种极端情况的一个中间方法。
混合模型中参数$\beta$的估计是完全忽视数据的结构和通过估计$j$个不同的模
型来全部体现数据结构两种方法的一个折衷方案。混合模型估计从$j$个不同模型
朝一个聚合模型方向收缩。混合模型得到的估计可以看作是来自个体模型的加权
评价。收缩得到的估计的均方误差优于聚合模型和个体模型的均方误差。线性混
合模型估计是最佳线性无偏预测(BLUP)(Pinero and Bates 2000; Ruppert, Wand
and Carroll
2003)[@pinheiro2000mixed; @ruppert2003semiparametric]。因此，当$j$个个
体之间具有显著的差异时，依据均方误差原则，混合模型就提供了最佳拟合。

非线性可以看作是另一种形式的组间异质性。节点之间的数据就形成了一个组。
线性拟合与聚合模型类似，没有考虑可能存在的局部变异性。这个聚合模型忽视
内在结构，使用一个参数来描述$x$ 与 $y$ 之间的关系。这个拟合是最简约的，但
其忽视了$x$与 $y$之间关系在不同节点之间的差异。如果变异确实存在，那么线
性拟合是有偏的。一个标准样条模型就是一个没有聚合的模型。此时，我们对每
个节点之间的数据都得到一个参数。这样得到的模型将非常确切的反映了局部变
异性，但是在节点之间的数据不多时，得到的估计将具有较大的变异性。与线性
模型和标准样条模型不同，光滑样条模型与混合模型具有类似的结构，其考虑了
局部变异性但同时从所有的节点段之间“借力”。这表明，光滑样条估计是均方
误差意义上的最佳估计。光滑样条估计是具有非线性导致的异质性模型的最佳线
性无偏预测(BLUP)，其从一个高度局部性的拟合向全局估计收缩。

样条回归模型(具有线性基)可以表示为： 
$$f(x_{i})=\beta_{0}+\beta_{1}x_{i}+
  \sum_{k=1}^{K}\beta_{k}^{*}(x_{i}-c_{k})_{+}+\varepsilon$$ 
其中
$$
  (x_{i}-c_{k})_{+}= \left \{
    \begin{array}{lr}
      0 & x \leq c_{k}\\
      x-c_{k} & x > c_{k}
    \end{array}
    \right.$${#eq:114-1}
表示节点在$c_{k}$的分段线性拟合。下面把方程中的每一项写成矩阵形式： 
$$\label{eq:116}
  \boldsymbol X = \left [
    \begin{array}{cc}
      1 & x_{1} \\
      \vdots & \vdots \\
      1 & x_{n}
    \end{array}
  \right ],
  \boldsymbol Z = \left [
    \begin{array}{ccc}
    (x_{1}-c_{1})_{+} & \ldots & (x_{1}-c_{k})_{+} \\
    \vdots & \ddots & \vdots \\
    (x_{n}-c_{1})_{+} & \ldots & (x_{n}-c_{k})_{+}
  \end{array}
\right ]$$ 
$$\boldsymbol \beta= \left [
    \begin{array}{c}
      \beta_{0}\\
      \beta_{1}
    \end{array}
  \right],
  \boldsymbol \beta^{*}= \left [
    \begin{array}{c}
    \beta_{1}^{*}\\
    \vdots\\
    \beta_{k}^{*}
  \end{array}
\right],
\boldsymbol \varepsilon =
\left [
  \begin{array}{c}
    \varepsilon_{1}\\
    \vdots\\
    \varepsilon_{n}
  \end{array}
\right].$$
其中向量$\boldsymbol \beta^{*}$表示分段函数的系数。使用上面的这些记号就可以把
方程写成矩阵形式 
$$\boldsymbol {y=X\beta+Z\beta^{*}+\varepsilon}.$${#eq:old-117}
为了把线性样条模型改写成混合模型，需要 
$$\label{eq:118}
  \boldsymbol u= \left[
    \begin{array}{c}
      u_{1}\\
      \vdots\\
      u_{K}
    \end{array}
  \right],$$ 
$\boldsymbol u$是随机效应向量，每一个元素都来自于正态分布
$\mathcal{N}(0,\sigma_{u_{k}}^{2})$。我们可以把改写成以 下混合模型：
$$\label{eq:119}
  \boldsymbol{y=X\beta+Zu+\varepsilon}.$$
这两个模型的差异在于混合模型中每个节点的系数用随机效应来代替。方程的解为：
$$\label{eq:120}
  \boldsymbol {\widehat f} =\boldsymbol C(\boldsymbol{C'C}+\lambda^{2} \boldsymbol D)^{-1}\boldsymbol{C'y}$$
其中$\boldsymbol{C=[XZ]}$，$\boldsymbol{D}=\text{diag}(0,0,1,\cdots,1)$，
$\lambda^{2}=\sigma_{\varepsilon}^{2}/\sigma_{u}^{2}$。Ruppert, Wand and
Carroll(2003)证明了方程等价于 
$$\text{SS}(f,\lambda)=\sum_{i=1}^{n}[(y_{i}-f(x_{i}))]^{2}
  +\lambda \int_{x_{1}}^{x_{n}}f''(x)^{2}\text{d}x$${#eq:121}
这是光滑样条的表示形式。

光滑样条和混合模型之间的等价性具有重要意义。首先，这表明光滑样条拟合是 $x$ 和
$y$ 之间的非线性关系的BLUP。当存在非线性时，光滑样条拟合具有最小的均方误差。因此，
光滑样条在拟合和使用的参数数量之间提供了一个最佳权衡。第二，混合模型框架可以把
$x$ 与 $y$ 之间的非线性关系概念化为未观测的异质性。如果存在该未观测的异质性却未
被拟合，模型就存在设定误差。非参数回归提供了拟合这种异质性的工具。这样，非参数回
归背后的逻辑与混合模型背后的逻辑就没有多大区别。非线性是一种形式的异质性，对于这
种异质性，光滑样条提供了平衡拟合与使用参数个数之间的最佳估计。光滑样条的混合模型
表示非参数方法容易转换为贝叶斯估计框架，并且其更容易把光滑样条集成到标准混合模型中,具体
可以参见Ruppert, Wand and Carroll (2003)[@ruppert2003semiparametric]。

### 广义线性混合模型
像广义线性模型对线性模型的推广一样，广义线性混合模型是正态线性混合模型的推广。
设 $Y_i$ 是指数族随机变量，并有期望均值 $\mu_i$ ,广义线性混合模型可表示为：
$$g\left(\mu_{i}\right)=\mathbf X_{i} \boldsymbol{\beta}+\mathbf Z_{i} \mathbf b, \quad
  \mathbf b \sim \mathcal{N}\left(\mathbf{0}, \psi_{\theta}\right)$$

也就是说，GLMM是一个GLM，其中线性预测子依赖于一些正态随机效应 $\mathbf b$ 乘以随
机效应模型矩阵 $\mathbf Z$ 。从线性混合模型过渡到广义线性混合模型的主要困难是不
再可能准确地计算对数似然值，因为在 $\mathbf y$ 和 $\mathbf b$ 的联合密度中，对b积分
$\mathbf b$ 获得似然函数通常在分析方法上是不可行的。

一个有效的解决办法是使用在 $\hat {\mathbf b}$ 点的泰勒展开式，
$f(\mathbf{y},\mathbf{b} | \boldsymbol{\beta})$
可以写成
$$f(\boldsymbol{y} | \boldsymbol{\beta}) \simeq \int \exp \left\{\log f(\boldsymbol{y}, \hat{\boldsymbol{b}} | \boldsymbol{\beta})+\frac{1}{2}(\boldsymbol{b}-\hat{\boldsymbol{b}})^{\top} \frac{\partial^{2} \log f(\boldsymbol{y}, \boldsymbol{b} | \boldsymbol{\beta})}{\partial \boldsymbol{b} \partial \boldsymbol{b}^{\top}}(\boldsymbol{b}-\hat{\boldsymbol{b}})\right\} d \boldsymbol{b}
$${#eq:121-1}

这里忽略了泰勒展开式中的高阶项，而不是等于零的那些项。在当前情况下所需的海塞矩阵
是 $-\mathbf{Z}^{\top} \mathbf{W} \mathbf{Z} / \phi-\psi^{-1}$ ,其中 $\mathbf{W}$ 
是IRLS权向量，基于由$\hat {\mathbf b}$ 和 $\boldsymbol{\beta}$ 表示的 $\mathbf \mu$ 。因此有：
$$f(\boldsymbol{y} | \boldsymbol{\beta}) \simeq f(\boldsymbol{y}, \hat{\boldsymbol{b}} | \boldsymbol{\beta}) \frac{(2 \pi)^{p / 2}}{\left|\boldsymbol{Z}^{\top} \boldsymbol{W} \boldsymbol{Z}^/ \phi+\psi_{\theta}^{-1}\right|^{1 / 2}}
$${#eq:121-2}
这种积分近似称为“拉普拉斯近似”积分，用显式形式代替随机效应密度并取对数则有
$$l(\theta, \boldsymbol \beta) \simeq \log f(\boldsymbol y | \boldsymbol {\hat{b}}, \boldsymbol \beta)-\boldsymbol {\hat{b}}^{\top} \psi_{\theta}^{-1} \boldsymbol{\hat{b}} / 2-\log \left|\psi_{\theta}\right| / 2-\log \left|\boldsymbol Z^{\top} \boldsymbol W \boldsymbol Z/ \phi+\psi_{\theta}^{-1}\right| / 2 $$ {#eq:m3.16}

注意 [@eq:m3.16] 式中的直接依赖关系，等式右边通过 $\mathbf {\hat{b}}$ 和
$\mathbf{W}$ 依赖于 $\boldsymbol {\beta}$和 $\theta$ 。$\mathbf{W}$ 对
$\boldsymbol \beta$ 的依赖意味着相比LMM的情况， $\boldsymbol \beta$ 的MAP估计和
极大似然估计MLE不再完全对应。尽管如此，使用MAP估计值还是很方便的，因为使用GLM模型中
使用的IRLS方法的惩罚版本，可以很容易地计算出各参数值和相应的 $\boldsymbol{\hat
b}$。如果我们这样做，我们也可以定义拉普拉斯近似截面似然
$l_{p}(\boldsymbol{\theta})=l(\boldsymbol{\theta}, \hat{\boldsymbol{\beta}})$，
其中 $\hat{\boldsymbol{\beta}}$ 是给定 $\theta$ 时的MAP估计量。

如果 $\hat{\boldsymbol{\beta}}$ 是给定$\theta$ 时的MAP估计量，则有：
$$\begin{aligned} l_{r}(\theta) \simeq & \log f(\boldsymbol y | \hat{\boldsymbol b} , \hat{\boldsymbol \beta})-\hat{\boldsymbol b}^{\top} \psi_{\theta}^{-1} \hat{\boldsymbol b} / 2-\log \left|\psi_{\theta}\right| / 2 \\ &-\log \left|\begin{array}{cc}{\boldsymbol Z^{\top} \boldsymbol W \boldsymbol Z^{T} \phi+\psi_{\theta}^{-1}} & {\boldsymbol Z^{\top} \boldsymbol W \boldsymbol Z^{T} \phi} \\ {\boldsymbol X^{\top} \boldsymbol W \boldsymbol Z^{T} \phi} & {\boldsymbol X^{\top} \boldsymbol W \boldsymbol Z^{T} \phi}\end{array}\right| / 2+M \log (2 \pi) / 2 \end{aligned}$$ {#eq:3.17}

正如在线性混合模型中一样，可以数值优化 $l_{p}$ 或 $l_{r}$ 来得到 $\hat{\theta}$
， $\theta$ 的每次迭代值都要求计算相应的
$\hat{\boldsymbol{\beta}},\hat{\boldsymbol{b}}$ 。与线性情况相反，这些计算不再是
直接的，而是需要迭代，且惩罚IRLS方案通常在使用时更快速和可靠。拉普拉斯近似在
Davison(2003)或Wood(2015)中有更详细的讨论[@Davison2003;@Wood2015]。Shun和
McCullagh(1995)表明，如果随机效应的数量以不高于 $n^{l/3}$ 的速度增长，那么它通常
提供了有充分根据的推断[@Shun1995]。下面分别对惩罚IRLS和PQL方法进行介绍。

#### 惩罚IRLS
可以在IRLS算法中加入惩罚项来计算 $\hat {\mathbf b}$ 和 $\boldsymbol \beta$ 。
通过以下方式计算 $\hat {\mathbf b}$ 和 $\boldsymbol \beta$，
$$\hat{\boldsymbol{\beta}}, \hat{\boldsymbol{b}}=\underset{\boldsymbol \beta, \boldsymbol{b}}{\operatorname{argmax}} \log f(\boldsymbol{y}, \boldsymbol{b} | \boldsymbol{\beta})=\underset{\boldsymbol \beta, \boldsymbol{b}}{\operatorname{argmax}}\left\{\log f(\boldsymbol{y}, \boldsymbol{b} | \boldsymbol{\beta})-\boldsymbol{b}^{\top} \psi_{\theta}^{-1} \boldsymbol{b} / 2\right\} $$ {#eq:m3.18}

[@eq:m3.18] 式中不依赖于 $\boldsymbol b$ 和 $\boldsymbol \beta$ 的项已从最终对象即惩罚似然函数中剔除。为了简化符号，将
 $\boldsymbol b$ 和 $\boldsymbol \beta$ 写成向量形式：
$\mathcal{B}^{\top}=\left(\boldsymbol{b}^{\top},\boldsymbol{\beta}^{\top}\right)$，
并定义相应的模型矩阵和精度矩阵为
$$\boldsymbol \chi=(\boldsymbol Z,\boldsymbol X) \text { 和 } \boldsymbol S=\left[\begin{array}{cc}{\psi_{\theta}^{-1}} & {\boldsymbol0} \\ {\boldsymbol 0} & {\boldsymbol 0}\end{array}\right]
$${#eq:121-4}

包括了二次惩罚项的惩罚似然函数的海塞矩阵为$-\boldsymbol\chi^{\top}
\boldsymbol{W} \boldsymbol \chi/ \phi-\boldsymbol{S}$，其中$\boldsymbol{W}$ 是由
当前的 $\hat{\boldsymbol \mu}$ 推导出来的诊断权重矩阵，使用Fisher或Newton方法),
$\hat{\boldsymbol \mu}$ 反过来依赖于当前$\mathcal{B}^{[k]}$ 的估计值，则相应的梯
度向量可以写为：
$$\boldsymbol \chi^{\top} \boldsymbol{W}
\boldsymbol{G}(\boldsymbol{y}-\hat{\boldsymbol{\mu}})/\phi-\boldsymbol{S}
\mathcal{B}^{[k]}.$${#eq:121-5}

牛顿更新步骤有如下形式：
$$\mathcal{B}^{[k+1]}=\mathcal{B}^{[k]}+\left(\boldsymbol \chi^{\top} \boldsymbol{W} \boldsymbol \chi+\phi \boldsymbol{S}\right)^{-1}\left\{ \boldsymbol \chi^{\top} \boldsymbol{W} \boldsymbol{G}(\boldsymbol{y}-\hat{\boldsymbol{\mu}})-\phi \boldsymbol{S} \mathcal{B}^{[k]}\right\}$${#eq:121-6}
将$\mathcal{B}^{[k]}=\left(\boldsymbol \chi^{\top} \boldsymbol{W} \boldsymbol \chi+\phi \boldsymbol{S}\right)^{-1}\left(\boldsymbol \chi^{\top} \boldsymbol{W}\boldsymbol \chi+\phi \boldsymbol{S}\right) \mathcal{B}^{[k]}$
带入上式可得到
$$\mathcal{B}^{[k+1]}=\left(\boldsymbol \chi^{\top} \boldsymbol{W} \boldsymbol \chi+\phi \boldsymbol{S}\right)^{-1}\boldsymbol \chi^{\top}\boldsymbol{W} \{ \boldsymbol{G}(\boldsymbol{y}-\hat{\boldsymbol{\mu}})+\boldsymbol \chi\mathcal{B}^{[k]}\}$$
它可以立即被识别为惩罚加权最小二乘目标的最小值
$$\|\boldsymbol z-\boldsymbol \chi \mathcal{B}\|_{W}^{2}+\phi \mathcal{B}^{\top} \boldsymbol S \mathcal{B}= \left\| \boldsymbol z-\boldsymbol X \boldsymbol \beta-\boldsymbol Z \boldsymbol b \right\|_{W}^{2}+\phi \boldsymbol b^{\top} \psi_{\theta}^{-1} \boldsymbol b
$${#eq:121-7}
其中
$z_{i}=g^{T}\left(\hat{\mu}_{i}\right)\left(y_{i}-\hat{\mu}_{i}\right)+\hat{\eta}_{i}.$

综合上面讨论，惩罚IRLS算法过程可以归纳如下：

1\. 初始化
$\hat{\mu}_{i}=y_{i}+\delta_{i}$ 和 $\hat{\eta}_{i}=g\left(\hat{\mu}_{i}\right)$，
其中 $\delta_{i}$ 通常为0，但也可以是非零常数以保证 $\hat{\eta}_{i}$ 是有限的。然后
迭代以下两个步骤直到收敛。

2\. 计算 $z_{i}=g^{T}\left(\hat{\mu}_{i}\right)\left(y_{i}-\hat{\mu}_{i}\right) / \alpha\left(\hat{\mu}_{i}\right)+\hat{\eta}_{i}$ 
并且迭代权重
$$w_{i}=\frac{
  \alpha\left(\hat{\mu}_{i}\right)
}{
  \left\{g^{T}\left(\hat{\mu}_{i}\right)^{2} V\left(\hat{\mu}_{i}\right)\right\}
}$$

3\. 计算 $\hat{\boldsymbol b}$ 和 $\hat {\boldsymbol\beta}$ ，使得以下的加权最小
二乘对象最小，
$$\|\boldsymbol z-\boldsymbol X \boldsymbol \beta-\boldsymbol Z \boldsymbol b\|_{W}^{2}+\phi \boldsymbol b^{\top} \psi_{\theta}^{-1} \boldsymbol b$${#eq:121-9}
然后更新$\hat{\boldsymbol \eta}=\boldsymbol X\hat{\boldsymbol \beta}+ \boldsymbol Z\boldsymbol b$ 和 $\hat{\mu_i}=g^{-1}(\hat{\eta_i})$。

是否收敛可以根据惩罚的似然偏差或其梯度来判断。

#### PQL方法
优化拉普拉斯近似截面或有限对数似然所需的嵌套优化比较复杂，而且计算成本很高。因
此，执行一个惩罚IRLS迭代，每一步都基于以下工作混合效应模型估计$\theta,\phi$:
$$\boldsymbol z | \boldsymbol{b}, \boldsymbol{\beta} \sim \mathcal{N}\left(\boldsymbol{X}
  \boldsymbol{\beta}+\boldsymbol{Z} \boldsymbol{b}, \boldsymbol{W}^{-1}
  \phi\right), \boldsymbol{b} \sim \mathcal{N}\left(\boldsymbol{0}, \boldsymbol \psi_{\theta}\right)$${#eq:121-10}
  
其中用到了Fisher权重。也就是说，惩罚IRLS算法的步骤3中，
$\hat{\boldsymbol{\theta}}, \hat{\boldsymbol{b}}, \hat{\boldsymbol{\beta}},
\hat{\boldsymbol{\phi}}$是对工作线性混合效应模型进行拟合得到的。这种方法在混合效
应模型的框架下(Breslow和Clayton, 1993)被称为PQL(惩罚拟似然)方法[@Breslow1993]。

一个显而易见的问题是当 $\mathbf{z}|\mathbf{b}, \boldsymbol{\beta}$ 显然不服从正
态分布时，为什么使用正态线性混合模型或受限制的似然函数是有效的。对于工作模型，在
假定 $\boldsymbol z$ 服从正态分布时，考虑受限制的似然函数，可以得到：
$$2 l_{r}=-\left\| \boldsymbol z-\boldsymbol \chi \hat{\mathcal{B}}\right\|_{W} ^{2} /\phi-\hat{\mathcal{B}}^{\top} \boldsymbol S \hat{\mathcal{B}}-n \log \phi+\log |\boldsymbol S|_{+} -\log \left|\boldsymbol\chi^{\top}\boldsymbol W \boldsymbol\chi/ \phi+\boldsymbol S\right|-(n-M) \log (2 \pi) $$ {#eq:m3.19}

其中 $\log |\mathbf{S}|_{+}\left(=-\log |\psi|_{+}\right)$ 是$\boldsymbol S$的非零特征值
的乘积(广义行列式)，则REML估计量 $\phi$ 为
$$\hat{\phi}=\frac{\left\|\boldsymbol z-\boldsymbol \chi \mathcal{B} \right\|_{W}^{2}}{n-\tau} \text { 其中 } \tau=\operatorname{tr}\left\{\left(\boldsymbol\chi^{\top} \boldsymbol W \boldsymbol\chi^{/} \phi+\boldsymbol S\right)^{-1} \boldsymbol\chi^{\top}\boldsymbol W \boldsymbol\chi^{T} \phi\right\}$$

现在考虑QR分解 $\boldsymbol Q \boldsymbol R=\sqrt{\boldsymbol W} \boldsymbol \chi$ ，其中 $\boldsymbol Q$ 是列正交的，R是上三角的(这里用的是
Fisher权重)，令 $\boldsymbol f=\boldsymbol{Q}^{\top} \sqrt{\boldsymbol W} \boldsymbol z$ ，
则${\left\|\boldsymbol f-\boldsymbol R\mathcal{B}\right\|}^{2}+c=\left\|\boldsymbol z-\boldsymbol \chi \mathcal{B}\right\|_{W}^{2}$，
其中 $c=\left\|\boldsymbol z\right\|_{W}^{2}-\left\|\boldsymbol f\right\|^{2}$ 。有均值函数
$\mathrm{E}(\boldsymbol{f})=\boldsymbol{R} \mathcal{B}$， $\boldsymbol f$ 的协方差矩阵是
$\boldsymbol I \phi$ 。如果$n /(\mathrm{M}+p) \rightarrow \infty$，多元中心极限
定理表明 $\boldsymbol f$ 具有多元正态分布。所以没有假设$\boldsymbol z$的正态性,我们也可以基于
正态线性混合模型合理地推断和 $\mathcal{B}$ 和 $\theta$ 。正态线性混合为：
$$\boldsymbol{f} | \boldsymbol{B} \sim \mathcal{N}(\boldsymbol{R} \mathcal{B}, \boldsymbol{I} \phi) \quad \text {其中 } \boldsymbol{b} \sim \mathcal{N}\left(\mathbf{0}, \boldsymbol \psi_{\theta}\right)$$

并且受限制的似然函数为：
$$2 l_{r}={-\left\|\boldsymbol f-\boldsymbol R \hat{\mathcal{B}} \right\|^{2}}/{\phi}-{\hat{\mathcal{B}}}^{\top}\boldsymbol S \hat{\mathcal{B}}-p \log \phi+\log |\boldsymbol{S}|_{+} -\log \left|\boldsymbol{R}^{\top} \boldsymbol{R}/\phi+\boldsymbol{S}\right|-p \log (2 \pi)$$ {#eq:m3.20}

对于固定的 $\phi$ ,式 [@eq:m3.20] 和 [@eq:m3.19] 是相同的。除了相差可加的常数项,
他们将被相同的 $\theta$ 和 $\mathcal{B}$ 最大化。另外，不适合基于式 [@eq:m3.20]
作关于 $\phi$ 的推断，因为这将忽略 $\phi$ 包含在 $c$ 中的信息。但是，如果把以上
的Pearson估计量 $\hat{\phi}$
带入式 [@eq:m3.20] ，并最优化 $\theta$ 和 $\mathcal{B}$，那么可以得到使式 [@eq:m3.19] 最优的
 $\hat \theta$ 和 $\hat {\mathcal{B}}$ 和 $\hat{\phi}$。这就是PQL方法的证明。
 注意，我们可以以同样的方式使用工作模型的截面似然来证明。

在许多情况下，PQL是非常有效的，它生成的估计非常接近于基于完全拉普拉斯近似的估计，
但对于某些类型的数据，它是有问题的。首先，当Pearson 估计值较差时，如对过分散的低
均值计数数据进行建模时，性能可能较差。其次,有些PQL的实现使用相关标准线性混合模型
软件，但不能选择固定的 $\phi$ 。在许多情况下,估计一个假定已知的 $\phi$ 不是问题,
可以被认为是一个有用的模型检查，但对于二分类数据，由于几乎没有可用来估计 $\phi$
的信息，所以会导致性能较差。第三，每个随机效应只有几个观察值的情况破坏了PQL的中
心极限定理。最后一个普遍的缺点是，我们不能得到模型真正的受限的或截面似然函数，因
此基于这些模型函数计算AIC和BIC等是不可能的。

#### 估计量分布
由于$\boldsymbol {A}_{\theta}^{-1} = \boldsymbol {W}^{-1} \phi$，可以得到作为关于
$\boldsymbol {\beta}$ 的近似推断的大样本分布结果，以及 $\boldsymbol b$ 的预测分布。
$$\hat{\boldsymbol{\beta}} \sim \mathcal{N}\left(\boldsymbol{\beta},\left\{\boldsymbol{X}^{T}\left(\boldsymbol{Z} \psi \boldsymbol{Z}^{T}+\boldsymbol{W}^{-1} \phi\right)^{-1} \boldsymbol{X}\right\}^{-1}\right)$$
尽管更倾向于用基于[@eq:m21}式的大样本估计结果：
$$\mathcal{B} | \boldsymbol{y} \sim \mathcal{N}\left(\hat{\mathcal{B}},\left(\boldsymbol\chi^{T} \boldsymbol{W} \boldsymbol\chi/ \phi+\boldsymbol{S}\right)^{-1}\right)$$ {#eq:m21}
但由第二个大样本结果推导的 $\boldsymbol{\beta}$ 的协方差矩阵再次对应于第一个大样本结
果的 $\boldsymbol{\beta}$ 的协方差矩阵。

正如在线性模型的情况下类似，我们可以使用大样本结果
$$\hat{\boldsymbol{\theta}} \sim \mathcal{N}\left(\boldsymbol{\theta}, \hat{\mathcal{I}}^{-1}\right)$$
其中 $\hat{\mathcal{I}}$ 是基于PQL工作线性混合模型或完全拉普拉斯近似的截面或受限制的
极大似然的负海赛矩阵。


## 广义可加混合模型(GAMM) {#sec:gamm}
### 广义可加混合模型提出背景

如同线性回归模型可以推广到广义线性模型一样，线性混合模型也可以推广到广义线性混合
模型(GAMM)。上面介绍的广义线性混合模型(GLMM)(Breslow and Clayton, 1993)为各种过
度离散和相关因变量的参数回归提供了统一的似然框架[@Breslow1993]。这种类型数据在许
多领域研究中都会出现，例如纵向数据研究，抽样调查，临床医学和疾病绘图(desease
mapping)。GLMM推断的主要困难在于完全似然分析中难以解决多重数值积分问题。各种近似
推断方法(Breslow and Clayton, 1993; Lee and Nelder, 1996; Lin and Breslow, 1996)
和基于EM算法和Gibbs抽样的贝叶斯方法(McCulloch, 1997; Zeger and Karim, 1991)被用
于解决这个问题[@Breslow1993; @lee1996hierarchical;@lin1996bias;@mcculloch1997maximum; @zeger1991generalized]。
关于完全最大似然估计的讨论可以参见Aitkin(1999)[@aitkin1999general]。

GLMM一个关键特征是其使用参数均值函数来对自变量的效应进行建模，并通过向线性预测子
添加随机效应来拟合过离散化和相关性。然后，这个参数均值函数的假设不一定总是正确的，
因为合适的自变量函数形式事先并不知道，因变量和自变量之间的依赖关系有可能具有复杂
的形式。因此，向GLMM模型中添加非参数均值函数项，建立相关数据的非参数回归模型具有
实际意义。这将允许因变量和自变量之间具有更灵活的函数依赖关系。

对于独立数据，使用核或者样条等方法的非参数回归文献很多(Hardle, 1990;
Green and Silverman,
1993)[@hardle1990applied; @green1993nonparametric]。Hastie and
Tibshirani (1990)的广义可加模型应用非常广
泛[@hastie1990generalized]。然而，对于相关数据非参数回归的研究却非
常有限。大部分研究都局限于具有正态因变量的纵向数据并带有一个非参数函
数(Hart, 1994; Rice and Silverman,
1991)[@hart1994automated; @rice1991estimating]。还有一些研究在线性混
合模型中加入一个非参数时间函数(Zeger and Diggle, 1994; Zhang *et al.*,
1998; Diggle,Verbyla,
1998)[@zeger1991generalized; @Zhang1998; @diggle1998nonparametric]
。对于非正态纵向数据，Wild and Yee (1996)和Berhane and
Tibshirani(2008)把广义可加模型推广到广义估计方程(Liang and Zeger,
1986)[@yee1996vector; @berhane2008generalized; @liang1986longitudinal]
。而在混合模型框架内研究非正态相关自变量的非参数回归文献不多。参
见Verbyla(2002)关于独立非正态数据广义线性模型中光滑样条的混合模型公式的
讨论[@verbyla2002analysis]。

相关数据的非参数回归面临许多新的问题。除了必须开发非参数函数的估计程序，
我们还必须考虑如何估计相关参数。已被许多学者(Green and Silverman, 1994;
Wahba, 1978)强调过的至关重要的问题是如何选择好的光滑参数和带宽参
数[@green1993nonparametric; @wahba1978improper]。这些问题的相关研究
很少，特别是相关参数和光滑参数的估计。传统光滑参数估计方法，数据驱动方
法面临着许多新的问题。例如，尽管交叉验证方法(Rice and Silverman,
1991)对于相关数据的光滑参数选择是一个合理的方
法[@rice1991estimating]，但其通常计算强度很大，而且接下来相关参数
估计非常困难(Zeger and Diggle, 1994)[@zeger1994semiparametric]。此
外，交叉验证方法对于交叉设计和空间数据无效。因此，开发同时对模型所有参
数进行估计的系统方法具有重要意义。

Lin，Zhang(1999)提出广义可加混合模型(GAMM)来解决这些问
题[@Lin1999]。GAMM是根据Hastie and Tibshirani (1990)的思
想对GLMM的可加模型推广[@hastie1990generalized]。这种新类型模型使用
可加非参数函数来拟合自变量的效应，并通过对可加预测子增加随机效应来应
对数据中的过离散化和相关性。GAMM可以用于分组、层次和空间数据。

### 广义可加混合模型设定
假设$n$个个体的第$i$个观测值的因变量$y_{i}$条件独立，并且期望
为$\mathbb{E}(y_{i}|\boldsymbol{b})=\mu_{i}^{\boldsymbol{b}}$，方差为
$\text{var}(y_{i}|\boldsymbol{b})=\phi m_{i}^{-1}v(\mu_{i}^{\boldsymbol{b}})$，其中
$v(\cdot)$是设定的方差函数，$m_{i}$是权重，$\phi$是尺度参数。那么广义
可加混合模型为 
$$g(\mu_{i}^{\boldsymbol{b}})=\boldsymbol{X_{i}\beta} + f_{1}(x_{1i}) + f_{2}(x_{2i})
  + \cdots + \boldsymbol{Z_{i}b},$${#eq:121-1-1}

其中$g(\cdot)$是联接函数，$\mu_{i}^{\boldsymbol{b}}$是 $y$
的条件期望，$\boldsymbol{\beta}$ 是固定效应参数向量，$\boldsymbol{X_{i}}$是固定
效应设计矩阵，$f_{j}$是自变量$x_{k}$的光滑函数，$\boldsymbol{Z_{i}}$是随机效应
的设计矩阵，$\boldsymbol{b \sim \mathcal{N} (0, \Psi)}$ 是随机效应变量，其中方差
协方差阵$\boldsymbol{\Psi}$ 一般未知而需要估计。

在模型中，线性预测子和非参数函数共同来拟合自变量的固定效应，而随机效应用来拟合观
测值之间的相关关系。当光滑函数$f(\cdot)$都为线性函数时，那么此时GAMM就变化为GLMM。
GAMM可以用于不同的相关数据类型，如纵向数据，分层数据，空间数据等。对于不同的数据
类型，我们对随机效应$\boldsymbol b$设定不同的方差协方差矩阵结构，具体可以参考
Zeger，Diggle(1994)，Zhang *et al.*(1998)(纵向数
据)[@zeger1994semiparametric;@Zhang1998]，
Lin，Breslow(1996)(分层数据)[@lin1996bias]和Cressie(1993)，Breslow，
Clayton(1993)(空间数据)[@cressie1993statistics; @Breslow1993]。

Lin，Zhang(1999)使用光滑样条来估计非参数函数，使用边际拟似然同时给出光
滑参数和方差成分的估计[@Lin1999]。边际拟似然方法是限制最
大似然(REML)方法的推广。REML方法被Wahba(1985)和Kohn *et
al.*(1991)用在经典非参数回归模型
中[@wahba1985comparison; @kohn1991performance]，被Zhang *et al.*(1998)，
Brumback and Rice(1998)和Wang(1998)用在正态非参数混合模型 中
[@Zhang1998; @brumback1998smoothing; @wang1998smoothing]
，这些学者把光滑参数看作是额外的方差成分。因为在最大化目标函数时需要求
数值积分，双重惩罚拟似然(DPQL)被用来作近似推断。上面方法的一个关键特征
是在统一的参数混合模型框架下对GAMM的所有部分同时进行了系统推断。具体地
讲，GAMM的非参数函数、光滑参数和方差成分的估计可以通过已有的统计软件拟
合一个GLMM来得到。当数据是稀疏的时候(例如二分类数据)，方差成分的DPQL估
计具有一定的偏倚，这个偏倚可以通过一定的方法修正以改进这个估计。关于广
义可加混合模型的估计和推断更详细的讨论可以参 考Lin，Zhang(1999)和
Wood(2006)[@Lin1999; @wood2006generalized]。

总之，半参数回归方法容易推广到混合模型。考虑到混合模型中交互项的普遍存在，非参数
技术为描述第一层和第二层之间的非线性交互效应提供了灵活的方法。但是，半参数的这种
推广并不是没有代价的。混合模型与标准模型相比，是一种计算强度更大的方法，而GAMM更
是增加了这种计算强度。一般地，我们注意到的差别就是在计算时间上多花几秒而已。然而，
在估计GAMM经常碰到的一个问题就是收敛问题。由于在估计GAMM时计算变得更困难，模型可
能不能收敛。如果发生这种情况，我们必须采取更简单的模型来拟合数据。下面给出广义可
加混合模型的一个特例，半参数混合模型。

### 特例：半参数混合模型设定
最近，半参数混合模型得到了广泛关注。当建立混合模型时，我们一般使用线性函数形
式。与其他参数模型一样，对于一个给定的混合模型我们并没有先验的理由认为线性函数形
式是正确的。尽管线性函数形式有可能是合适的，我们仍然可以使用非参数方法来诊断和拟
合混合模型中的非线性关系。这一部分我们主要从半参数方法如何融入到混合模型的角度来
讨论半参数混合模型。下面我们给出半参数混合模型的模型设定。一般地，半参数混合模型
具有以下形式
$$
  y_{i}=\boldsymbol{X_{i}\beta} + f_{1}(x_{1i}) + f_{2}(x_{2i})
  + \cdots + \boldsymbol{Z_{i}b} + \varepsilon_{i}$${#eq:additive-mixed}
其中 $y_{i}$ 是因变量， $\boldsymbol{\beta}$ 是固定效应参数向量，
 $\boldsymbol{X_{i}}$ 是固定
效应设计矩阵， $f_{j}$ 是自变量 $x_{k}$ 的光滑函数， $\boldsymbol{Z_{i}}$ 是随机效应
的设计矩阵， $\boldsymbol{b \sim \mathcal{N} (0, \Psi)}$ 是随机效应变量，其中方差
协方差阵 $\boldsymbol{\Psi}$ 一般未知而需要估计， $\boldsymbol{\varepsilon \sim \mathcal{N}(0,\Lambda)}$ 是误差向量，其由 $\varepsilon_{i}$ 堆积而成，一般假设其方差
协方差矩阵具有比较简单的形式。

## 贝叶斯广义可加混合模型
广义加性混合模型（GAMM）为涉及横截面，纵向和空间数据现实复杂情况下的回归分析提供
了广泛而灵活的框架。它们扩展了广义线性模型，通过将未知的度量自变量，时间尺度和空
间自变量的光滑函数以及随机效应添加到预测子的一般线性固定效应部分。在下面讨论的贝
叶斯广义可加混合模型中，所有这些影响因素以及光滑参数或其他超参数都被认为是随机的，
并且通过为它们设置适当的先验分布来获得特定模型。对于GAMM模型的统计推断的参数方法
有一些缺陷和限制，尤其是因变量不服从正态分布时。关于GAMM模型，Lin和
Zhang(1999)在扩展Breslow和Clayton(1993)以及Breslow和Lin（1995）广义线性混合模型
成果的基础上，使用光滑样条和双重惩罚拟似然（DPQL）法提出了合理的推断
[@Lin1999;@Breslow1993;@Breslow1995]。但他们同时也指出，与GLMM模型相似，模型推断
同样存在偏差问题，尤其是对于二分类因变量和存在随机效应的模型，因此MCMC方法成
为另外一种具有吸引力的选择。

对于正态因变量，Gibbs采样可用于基于光滑先验的完全贝叶斯分析;参见Wong和Kohn(1996)，
他们在不包含任何非结构化或空间随机效应的加性模型中使用状态空间或样条的动态模型。
或者是Hastie和Tibshirani(2000)，他们将Gibbs采样器推导作为贝叶斯的逆拟合过程
[@Wong1996;@Hastie2000]。Smith and Kohn(1996)和Denison等人(1998)提出了使用回归样
条或更一般的分段多项式的贝叶斯基函数方法，同样没有随机效应
[@Smith1996;@Denison1998]。我们在实现中使用更直接的方法，利用具有置信区间的后
验精度矩阵;参见Rue(2000)或Lang and Brezger(2000)[@Rue2000]。

对于基本的非正态模型，需要比Gibbs采样更通用的MCMC技术。而现有的建议方法和实践经
验还存在不足。Hastie和Tibshirani(2000)为广义可加模型扩展了MH类算法，但没有给出任
何关于性能的例子或陈述[@Hastie2000]。Mallick等人(2000)提出了一种广义线性模型的贝
叶斯多元自适应回归样条方法，作为Denison等人(1998)贝叶斯曲线拟合方法的扩展，但正
如他们所说，采样器收敛速度较慢[@Mallick2000;@Denison1998]。由Biller(2000)开发的，
用于半参数广义线性模型的自适应回归样条函数的可逆MCMC算法似乎有更好的收敛特性,并
可能扩展用于GAMM类模型[@Biller2000]。

贝叶斯非参数函数估计和贝叶斯半参数函数估计的快速发展主要基于两个概念：(1)自适应
基函数方法和(2)光滑先验。在基函数方法中，可以选择不同的先验分布以控制基函数系数
的显著性（例如Smith和Kohn,1996[@Smith1996]，分段常数函数或回归样条的节点的数
量和位置（Denison等,1998;Biller,2000)[@Denison1998;@Biller2000]，或者一个空
间背景下空间域的划分（Heikkinen和Arjas，1998; Knorr-Held和RafBer，2000）[@Heikkinen1998;@Knorrheld2000]。光滑先验方法可以被称为随机惩罚似然方法。光滑先
验方法主要是通过为参数设置不同种类或光滑度的先验分布来解决问题。这些概念在动态模
型中的贝叶斯光滑样条（Hastie和Tibshirani，2000）和马尔可夫随机场模型中的空间光滑
等方面都有所应用[@Hastie2000]。Besag等以及Fahrmeir和Lang将这些
概念结合起来，对广义可加混合模型进行统一处理
[@Besag1991;@Fahrmeir2001;@Fahrmeir2001a]。由于光滑先验分布服从一般的多元正态分
布，所以对于后验分布的推断可以通过有效的MCMC方法进行。 最后，Lang和Brezger（2001）
开发了贝叶斯P样条模型，可以将其视为基函数和光滑先验方法的组合[@Lang2001]。

贝叶斯广义可加混合模型为时间相关或空间相关数据的回归分析提供了强大的工具。但在实
际应用中，通常会出现以下一些问题：基于观察到的数据，内在结构（包括自变量，时间和
空间的加性效应）在模型中能体现多少？是否有可能区分建立光滑空间结构的空间相关随机
效应和应该捕获未观察到的异质性的不相关的随机效应？假设有一个正确的基础回归函数，
关于估计偏差和方差，我们可以得出什么？ 信噪比或方差 - 方差比的影响是什么？ 不同
类型的因变量所带来的影响有多大？要为实际中的复杂模型找到这些问题的答案，仅分析
结果是不够的。Smith，Wong和Kohn（1998），Smith和Kohn（1996）以及Ber nardinelli，
Clayton和Montomoli（1995）等人对这些问题进行了初步研究
[@Smith1998;@Smith1996;@Bernardinelli1995]，Fahrmeir和Lang（2001a，b）通过模拟研
究，对这些问题在经验基础上进一步给出部分答案。下面的贝叶斯广义可加混合模型内容主要参考了
Fahrmeir和Lang（2001a，b）的两篇文章[@Fahrmeir2001;@Fahrmeir2001a]。

### 贝叶斯广义可加混合模型
广义线性模型假设，给定自变量 $w$ ，因变量 $y$ 的分布属于指数族，并且 $\mu=E(y|w)$ ，
线性预测子为 $\eta =\gamma^{T} w$ ，连接函数 $\mu = h(\eta)$ 将
 $\mu$ 与 $\eta$ 连接起来。这里 $h$ 是一个已知的单调函数，并且
$\gamma=\left(\gamma_1,\ldots,\gamma_q\right)$ 是要估计的未知回归系数的向量。广义
可加混合模型通过灵活的半参数可加性预测子替换简单的参数线性预测子来扩展GLM模型。
$$\eta=f_{1}\left(x_{1}\right)+\cdots+f_{p}\left(x_{p}\right)+
\gamma^{T} w+b_{g}$$

其中未知函数 $f_{1}, \ldots, f_{p}$ 是连续自变量、时间尺度和空间数据的光滑函数。
参数 $b_{g}, g \in \{1,\ldots G\},$ 代表互不相关的随机效应，主要用来捕捉未观测到的
异质性。在大多数情况下，分组变量是标识不同单元或集群的索引。它也可以是表示不同空
间位点的指标，最后形成空间异质性。一种常见的方法是将空间效应 $f_{spat}（s）$ 
( $s \in\{1, \ldots, S\}$ 表示一个空间内的不同位置)分解成平滑的结构化部分 $f_{str}
（s）$ 和非结构化的随机效应 $b_{s}$ 。加法分解的合理性
$f_{spat}(s)=f_{str}(s)+b_{s}$ 在于空间效应通常是许多潜在的未观察到的影响因素的
叠加。其中一些可能具有强大的空间结构（结构化部分），其他可能仅在某个空间点存在
（随机效应）。我们也可以将时间尺度的
函数或一个连续自变量分解成为一个光滑部分和一个不相关的随机效应。

未知函数 $f_{1}, \ldots, f_{p}$ 的光滑先验取决于自变量的类型。连续自变量和
时间尺度的先验可以是随机游走先验（Fahrmeir和Lang，2001a），P样条先验（Lang
和Brezger，2001）和光滑样条先验（Hastie和Tibshirani，2000）
[@Fahrmeir2001;@Lang2001;@Hastie2000]。
总之，一个未知的平滑函数 $f$ 是可以表出的，更确切地说是对应的函数向量
$f=\left(f\left(x_{1}\right), \ldots, f\left(x_{n}\right)\right)$ ，它是设计矩阵
$\boldsymbol X$ 和未知参数向量 $\boldsymbol \beta$ 的乘积，即 
$f =\boldsymbol X \boldsymbol \beta$ 。系数向量 $\boldsymbol \beta$ 的所有先
验都具有相同的一般正态形式

$$\beta | \tau^{2} \propto \exp \left(-\frac{1}{2 \tau^{2}} \beta^{T} K \beta\right)$$ {#eq:m-bayes-1}

这意味着尽管 $\tau^{2}$ 遵循部分不正确的正态先验

$$\beta | \tau^{2} \sim \mathcal{N}\left(0, \tau^{2} K^{-}\right)$$ {#eq:m-bayes-2}

其中 $K^{-}$ 是惩罚矩阵 $K$ 的广义逆。函数 $f$ 的光滑量由方差参数 $\tau^{2}$ 控制。 
对于完全贝叶斯分析，可以在层次结构的另一个阶段引入 $\tau^{2}$ 的超先验。
这允许同时估计未知函数和光滑量。一个常见的选择是高度分散但适当的逆伽玛先验
 $\tau^{2}\sim \text{逆Gamma}(k,\lambda)$ 。（在正态可加混合模型 $y=\eta+\varepsilon$ 中，
先验也选择为 $var(\varepsilon)=\sigma ^2$ ）。

空间自变量的光滑函数 $f(x)$ 中，$x_{i}$ 表示在一个空间域内观测对象 $i$ 的位置，该光滑
函数也可以表示 $f=X \beta$ 。最简单的情况中， $\beta$ 的一个 具体值 $\beta_{s}$ 与 $f(s)$
是相等的，即 $f(\cdot)$ 在 $s$ 点的值。并且在 Besag et al. (1991) 中，$\boldsymbol \beta$
的先验被假设是马尔可夫随机场先验，这同样可以用在式 [@eq:m-bayes-1] 的一般形式中[@Besag1991]。

对于非结构化的随机效应，一个常用的先验假设是 $b_{g}$ 符合独立同分布，并服从正态形式，其
中需要有关于 $v^2$ 的高度离散的超先验。

显然，可加性光滑影响函数 $f_{1}, \ldots, f_{p}$ 间的差别是微小的。事实上，不是为函数 $f$ 
的随机游走指定例如一阶或二阶的先验，随机效应 [@eq:m-bayes-2] 的先验也可以指定。二者之间的
区别在于函数 $f$ 所允许的光滑量。对于随机效应先验的指定，允许连续参数或多或少地不受
限制地变化，而随机游走先验需保证连续参数在 $x$ 的范围内光滑地变化。

贝叶斯推断是基于模型的后验分布，在所有实际应用中，后验分布在数值上是难以处理的，
一般可以使用MCMC模拟进行后验分析。所使用的精确MCMC模拟技术在Fahrmeir和
Lang（2001b）中有详细描述，参见Hastie和Tibshirani（2000）关于正态因变量的部分
[@Fahrmeir2001a;@Hastie2000]。对于正态和分类probit模型，使用Gibbs采样可以进行后
验模拟。在其他情况下，基于条件先验（Knorr-Held 1999）或迭代加权最小二乘方法
（Gamerman，1997）的MH法也可以使用[@Knorrheld1999;@Gamerman1997]。

### 贝叶斯半参数混合模型
有观测值 $\left(y_{i}, x_{i1},\ldots, x_{i p},w_{i}\right),i=1,\ldots,n$ ,
 $y$ 是因变量， $x=\left(x_{1}, \ldots, x_{p}\right)$ 是表示连续自变量或空间
自变量构成的向量， $w$ 也表示自变量。

广义可加模型和半参数模型假定，给定
 $x_{i}=\left(x_{i1}, \ldots, x_{i p}\right)$ 和 $w_{i}$ 以及属于指数族的 $y_{i}$ ，
并且 $y_{i}$ 具有均值 $\mu_{i}=E\left(y_{i} | x_{i}, w_{i}\right)$ ，通过如下公式
$$\begin{array}{c}{\mu_{i}=h\left(\eta_{i}\right)} \\ {\eta_{i}=f_{1}\left(x_{i 
1}\right)+\ldots+f_{p}\left(x_{i p}\right)+w_{i}^{T} \beta}\end{array}$$ {#eq:m-bayes-4}
可将均值 $\mu_{i}$ 与半参数预测子 $\eta_{i}$ 相连接[@hastie1990generalized]。

 $h$ 是一个已知连接或已知的因变量函数, $f_{1}, \ldots, f_{p}$ 是自变量的未知光滑函数。
并且空间自变量 $x_{j}$ 的空间相关效应（随机效应）以$f_{j}\left(x_{i}\right)$ 的形式
被包含在模型中。如果自变量不足以解释研究单位间的异质性或者研究对象是纵向研究中具有相
关性的数据，则构建具有形式 [@eq:m-bayes-4] 的模型或许是不合适的。一种常见的处理这个问题的方法
是在预测子中加入随机效应。即产生具有如下形式预测子的GAMM模型
$$\eta_{i}=f_{1}\left(x_{i 1}\right) +\ldots+f_{p}\left(x_{i p}\right)+w_{i}^{T} \beta+b_{g_{i}}$$ {#eq:m-bayes-5}
其中 $b_{g_{i}}$ 表示特定个体或特定组的随机效应，如果在第 $g$ （$g=1,\ldots, G$）
组中存在第 $i$ 个观测个体，则 $b_{g_{i}}=b_{g}$ 。

### 贝叶斯广义可加混合模型中先验分布的设定
在贝叶斯半参数模型推断中，未知函数 $f_{1}, \ldots, f_{p}$ ，更准确的说是相应的函数估计
向量，以及参数 $\beta=\left(\beta_{1}, \ldots, \beta_{r}\right)$ 和随机
效应 $b=(b(1), \ldots, b(G))$ 都被认为是随机变量。观测模型被视为以这些随机变量为条件，
并且必须提前为模型设定合适的先验分布。

未知函数 $f_{1}, \ldots, f_{p}$ 的先验设置取决于自变量的类型和对 $f_j$ 光滑度的
经验判断。时标和连续自变量的先验分布是广义线性模型中常见的正态分布。参见Fahrmeir
和Tutz（1997）的第8章[@Fahrmeir1997]。空间自变量的先验基于马尔科夫随机场，参见
Besag(1974)和Besag等（1991）或者Besag和Kooperberg(1995)中的相关说明
[@Besag1974;@Besag1991;@Basag1995]。

#### 连续自变量和时标先验分布的选取
首先考虑具有相同空间观测数目 $x_{i}, i=1, \ldots, m, m \leqslant n$ 的连续自变量
$x$ ,按顺序排列 $x_{(1)}<\ldots<x_{(t)}<\ldots<x_{(m)}$ 可定义 $x$ 轴上的等距网格。
这种方法常用于以下情况，即每个时刻 $t$ 都对应自变量 $x$ ,并且网格点对应时间单位，如
周、月或是年，但通常 $x$ 可以是任意有序维数。定义 $f(t) :=f\left(x_{(t)}\right)$ ，
$$f=(f(1), \ldots, f(t), \ldots, f(m))^{T}$$
表示函数估计向量，则在时间趋势的分析案例中，常见的光滑函数的先验是一阶或二阶随机游走，
即
$${f(t)=f(t-1)+u(t)}$$ {#eq:m-bayes-6a}
或者
$${f(t)=2 f(t-1)-f(t-2)+u(t)}$$ {#eq:m-bayes-6b}
其中， $u(t) \sim \mathcal{N}\left(0 ; \tau^{2}\right)$ ，并且扩散先验 $f(1)\propto$ 常数，f(1)
和f(2) 也均正比于常数。式 [@eq:m-bayes-6a] 和[@eq:m-bayes-6b]都可作为光滑先验，惩罚过于粗糙的函数f。
一阶随机游走惩罚连续状态之间的 $f(t)-f(t-1)$突变，二阶随机游走惩罚偏离线性趋
势$2f(t-1)-f(t-2)$的偏差。注意，二阶随机游走是通过计算二阶差分得到的，即相邻一阶差分的
差分。在实践中，这两种先验的不同之处在于，二阶随机游走先验的估计函数往往更光滑一些。当
然，更高阶差分先验也是可能的。例如，如果自变量x是时间t(以月为单位)，那么季节性成分 $f(t)$ 
的一个常见先验光滑为：
$$f(t)+f(t-1)+\ldots+f(t-11)=u(t) \sim \mathcal{N}\left(0,\left.\tau\right|^{2}\right)$$ {#eq:m-bayes-7}

接下来考虑更为一般的空间观测数不相等的情况。令
$$x_{(1)}<\ldots<x_{(t)}<\ldots<x_{(m)}$$
其中，$m \leqslant n$ ，表示自变量 $x$ 的不同观测数目。对于 $f(t) :=f\left(x_{(t)}\right)$，
有函数估计向量：
$$f=(f(1), \ldots, f(t), \ldots, f(m))^{T}$$

随机游走或自回归先验也需做出调整来解释观测的不等间距 $\delta_{t}=x_{(t)}-x_{(t-1)}$。
一阶随机游走被定义为
$$\begin{array}{l}{f(t)=f(t-1)+u(t)} 
\\ {u(t)}{\sim \mathcal{N}\left(0;\delta_{t}\tau^{2}\right)}\end{array}$$ {#eq:m-bayes-8}
误差项的方差由 $\tau^{2}$ 变为 $\delta_{t}\tau^{2}$ 。二阶随机游走是
$$f(t)=\left(1+\frac{\delta_{t}}{\delta_{t-1}}\right) f(t-1)-\frac{\delta_{t}}
{\delta_{t-1}} f(t-2)+u(t)$$ {#eq:m-bayes-9}
其中 $u(t)\sim \mathcal{N}\left(0;w_{t}\tau^{2}\right)$ , $w_t$ 表示一个合理的权重。权重有以下
几种形式。对于一阶随机游走，权重形式最简单，即 $w_{t}=\delta_{t}$ 。权重还可以是
$$w_{t}=\delta_{t}\left(1+\frac{\delta_{t}}{\delta_{t-1}}\right)$$
这种形式考虑同时考虑了差距 $\delta_t$ 和 $\delta_{t-1}$ 。$\delta_{t-1}$ 由一阶差分
$$\frac{f(t)-f(t-1)}{\delta_{t}}-\frac{f(t-1)-f(t-2)}{\delta_{t}-1}$$
的差分产生，并假设彼此间独立。Berzuini和Larizza对二阶自回归先验给出了一个相关但不同的
方案(1996)[@Berzuini1996]。另一种可能性是基于Kohn和Ansley(1987)的工作，使用随机微分方程先验的状态空间表示[@Kohn1987]。
Biller和Fahrmeir(1997)遵循了这一观点，但与本文选择的先验相比，后验样本的收敛和综合表现
存在显著问题[@Biller1997]。

由于随机游动或其他自回归模型的马尔可夫设定，函数估计向量 $f$ 的先验似乎是以一种非对称的定
向方式定义的。然而，这些先验总是可以以非定向对称的形式重写。这是因为任何离散的马尔可夫过
程都可以用马尔可夫随机场的不受约束的形式来表示，即不仅包括以前的变量$f(t-1)、f(t-2)$，还
包括将来的变量 $f(t + 1)、f(t +2)$ 等。这说明对于整个向量 $f$ 以及先验 [@eq:m-bayes-8] 
 [@eq:m-bayes-9] 或者 [@eq:m-bayes-7] 的设定，均以正态先验为前提是不正确的，
$f\sim \mathcal{N}\left(0;\tau^{2} K^{-}\right)$ 中的 $K^{-}$ 表示含有置信区间的诊断精度或
者是惩罚矩阵 $K$ 的广义逆矩阵。如式 [@eq:m-bayes-8] 中一阶随机游走的惩罚矩阵是

$$K=\left(\begin{array}{cccccccc} 
\delta_2^{-1}&-\delta_2^{-1} & & & & & & \\
-\delta_2^{-1}&\delta_2^{-1}+\delta_3^{-1}&-\delta_3^{-1}\\
& -\delta_3^{-1}&\delta_3^{-1}+\delta_4^{-1}& \ &-\delta_4^{-1}\\
&  & & \ddots & & \ddots & &\\
&  & -\delta_{m-2}^{-1}& \ & \delta_{m-2}^{-1}+\delta_{m-1}^{-1}& &-\delta_{m-1}^{-1}\\
&  & &  & -\delta_{m-1}^{-1}& & \delta_{m-1}^{-1}+\delta_{m}^{-1}&-\delta_{m}^{-1}\\
&  &  &  &  &  &-\delta_{m}^{-1}&\delta_{m}^{-1}
\end{array} \right)
$$

若 $x$ 值是等间距的，则有
$$K=\left(\begin{array}{cccccccc}
1 & -1 &&&   & &&  \\ 
-1& 2&  & -1 &  &   &   \\
&  & \ddots &   & \ddots &  & \ddots&   \\
& &   & -1 &   & 2 &   & -1 \\
&   &  &  &    &-1 &   & 1
\end{array}\right)
$$

#### 空间自变量先验分布的选取
现在考虑空间自变量 $x$ ，其中 $x$ 的值表示连接的地理区域中的位置。例如，在失
业研究中，$x$ 代表了失业人口居住的地区。处理空间自变量的一种常见方法是假设相邻地点比两
个任意地点更相似。因此，对于有效的先验定义，必须为每个地点 $x_t$ 定义一组相邻点。
对于本文所考虑的地理数据，我们通常假设两个地点 $x_t$ 和 $x_j$ ;如果他们有共同的边界，他们就
是相邻点。但对相邻更复杂的定义也是可能的;参见Besag等人(1991)[@Besag1991]。我们为函数估计
 $f(t),t=1,\cdots,m$ ， $m$ 个不同地点 $x_j$ ,设定如下的空间光滑先验:
$$\begin{array}{l}{\qquad f(t) \,|\, f(j) \,\, j \neq t, \tau^{2} \sim
  N\left\{\sum_{j\in \partial_{j}} f(j) / N_{t}, \tau^{2} / N_{t}\right\}} \end{array}$$ {#eq:m-bayes-10}

其中 $N_{t}$ 表示邻近地点的数目， $j \in \partial_{t}$ 表示地点 $x_{j}$ 与地点 $x_{t}$ 
相邻。因此 $f(t)$ 的条件均值是相邻地点函数估计的未加权平均。对于空间数据，由于 $x_t$ 之间没
有固定的顺序，所以同时间或连续自变量一样，其设定是无定向的。

一个更一般的先验可由式 [@eq:m-bayes-11] 给出，式 [@eq:m-bayes-10] 是式 [@eq:m-bayes-11] 的特例。
$$f(t) | f(j) \,\,j \neq t\,, \tau^{2} \sim \mathcal{N}\left\{\sum_{j \in \partial_{t}} w_{t j}/
  w_{t+} f(j), 1 / w_{t+} \tau^{2}\right\}$$ {#eq:m-bayes-11}
其中 $w_{tj}$ 是已知的相等权重，加号表示其它下标的总和。

这种先验称为正态固有自回归;参见Besag et al.(1991)和Besag and Kooperberg(1995)[@Besag1991;@Basag1995]。当指定
$w_{tj}=1$ ，得到特例式 [@eq:m-bayes-10] ，使得 $x_t$点的每个相邻点有相等的权重。不相等
的权重可以基于相邻地点的共同边界长度或两个地点的中心点距离进行设置:详情见Besag等人(1991)[@Besag1991]。
然而，本文的应用仅限于式 [@eq:m-bayes-10] 所示的邻近权重先验。

在自回归先验[@eq:m-bayes-8] ，[@eq:m-bayes-9] 或者 [@eq:m-bayes-7]的情况中，[@eq:m-bayes-11]
可以写为关于惩罚矩阵的形式，即
$$f|\tau^{2} \propto \exp \left(-\frac{1}{2 \tau^{2}} f^{T} K f\right)$$ {#eq:m-bayes-12}
其中元素 $K$ 通过以下方式给出
$$k_{t t}=w_{t+}$$
并且
$$k_{t j}=\left\{\begin{array}{ll}{-w_{t j}} & {j \in \partial_{t}} \\ {0} & {\text { 
其他 }}\end{array}\right.$$
通常这个先验是不恰当的，因为 $K$ 非满秩，因此不可逆。

对于连续自变量或空间自变量的函数$f$，其先验的密切形式相似性允许有一个统一的MCMC算法，该
算法本质上依赖于惩罚矩阵$K$，并且实际上独立于自变量的类型和光滑的定义。

#### 超先验假设
对于完全贝叶斯分析，在层次结构中进一步引入了方差的超先验。这允许同时估计未知函数
和光滑度。常见的选择是高度分散的逆伽玛先验
$$p\left(\tau^{2}\right) \sim \operatorname{IG}(a ; c)$$

$a$ 和 $c$ 的一个可能的选择是,例如 $a =c = 0.0001$ ， $a$ 和 $c$ 非常小，这导致
方差参数的先验几乎是离散的。例如，Besag等人(1995)提出了一种替代方案，为
$a=1,c=0.005$ 。
选择这样一个高度分散但合适的先验可以避免由不合适的先验引起的问题
[@Besag1995]。Hobart和Casella(1996)讨论了线性混合模型的这类问题[@Hobert1996]。然
而，由于估计结果往往对超先验的选择很敏感，特别是在数据是稀疏时，所以一般需要进行
敏感性分析。

对于固定效应参数 $\beta_{1}, \ldots, \beta_{r}$ ，一般假定独立的离散先验
 $p\left(\beta_{j}\right) \propto$ 一个常数， $j=1,\cdots,r$ （即
 $p\left(\beta_{j}\right)$ 正比于一个常数）。固定效应参数先验还可以是高度离散的正
态先验。随机效应的先验是 $b_{g}$ 满足独立同分布的正态假定。
$$b_{g} | v^{2} \sim \mathcal{N}\left(0, v^{2}\right), \quad g=1, \ldots, G$$

并且为 $v^{2}$ 再定义一个高度离散的超先验。接下来分别定义
$$f=\left(f_{1}, \ldots, f_{p}\right), \qquad \tau^{2}=\left(\tau_{1}^{2}, \ldots, 
\tau_{p}^{2}\right), \qquad \beta=\left(\beta_{1}, \ldots, \beta_{r}\right), \quad 
b=\left(b_{1}, \ldots, b_{G}\right)$$ 

表示函数估计、方差效应、固定效应和随机效应的参数向量。于是便可以通过以下的条件独立假设完
成贝叶斯模型的设定：

（a）对于给定的自变量和参数 $f$ 、 $\beta$ 、 $b$ ,观测对象 $y_i$ 是条件独立的；

（b）先验 $p\left(f_{j} | \tau_{j}^{2}\right), j=1, \ldots, p$ 是条件独立的；

（c）固定效应和随机效应的先验以及超先验 $\tau_{j}^{2}, j=1, \ldots, p$ 是彼此独立的。

<!-- # 参考文献 {-} -->
<!--[//]: # (\bibliography{Bibfile})-->
	
